"""
pages/student/my_reports.py - Version CORRIGÃ‰E pour le champ pourcentage manquant
===============================================================================
CORRECTION : Gestion dÃ©fensive des champs manquants (pourcentage, note_maximale, etc.)
"""

import streamlit as st
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from utils.data_manager import get_evaluations_list, clear_all_cache
from utils.display_helpers import display_header

def show():
    """Page tÃ©lÃ©chargement de rapports avec vÃ©rification de publication et gestion dÃ©fensive"""
    if not st.session_state.get('student_logged_in', False):
        st.warning("âš ï¸ Veuillez vous connecter d'abord")
        return
    
    student_info = st.session_state.get('student_info', {})
    
    display_header("ğŸ“„ Mes Rapports")
    
    # CHARGEMENT DES Ã‰VALUATIONS CORRIGÃ‰ES ET PUBLIÃ‰ES
    evaluations = get_evaluations_list()
    published_evaluations = _load_published_student_evaluations(evaluations, student_info)
    unpublished_evaluations = _load_unpublished_student_evaluations(evaluations, student_info)
    
    if not evaluations:
        st.info("ğŸ“­ Aucune Ã©valuation trouvÃ©e")
        if st.button("ğŸ”„ Actualiser les donnÃ©es"):
            clear_all_cache()
            st.rerun()
        return
    
    # AFFICHAGE DU STATUT DES RAPPORTS
    _show_reports_status(published_evaluations, unpublished_evaluations)
    
    # AFFICHAGE DES RAPPORTS DISPONIBLES (PUBLIÃ‰S)
    if published_evaluations:
        st.markdown("---")
        st.subheader(f"ğŸ“Š {len(published_evaluations)} Rapport(s) Disponible(s)")
        
        # LISTE DES RAPPORTS DISPONIBLES
        for eval_result in published_evaluations:
            eval_info = eval_result['evaluation_info']
            _display_report_section(eval_result, eval_info, student_info)
    
    # AFFICHAGE DES RAPPORTS NON DISPONIBLES (NON PUBLIÃ‰S)
    if unpublished_evaluations:
        st.markdown("---")
        _show_unpublished_reports_section(unpublished_evaluations)

def _normalize_student_report_result(result, eval_info):
    """âœ… NOUVELLE FONCTION : Normalise un rÃ©sultat Ã©tudiant pour les rapports"""
    
    # RÃ©cupÃ©rer les valeurs avec des dÃ©fauts sÃ»rs
    note_totale = result.get('note_totale', 0.0)
    note_maximale = result.get('note_maximale', eval_info.get('note_totale', 20))
    
    # Calculer le pourcentage si manquant
    if 'pourcentage' not in result or result['pourcentage'] is None:
        pourcentage = round((note_totale / note_maximale) * 100, 1) if note_maximale > 0 else 0.0
        result['pourcentage'] = pourcentage
    
    # S'assurer que les champs essentiels existent
    if 'note_maximale' not in result:
        result['note_maximale'] = note_maximale
    
    # Normaliser les champs optionnels
    result['etudiant_nom'] = result.get('etudiant_nom', 'Inconnu')
    result['etudiant_prenom'] = result.get('etudiant_prenom', 'Inconnu')
    result['commentaires_generaux'] = result.get('commentaires_generaux', result.get('commentaires', ''))
    result['points_forts'] = result.get('points_forts', [])
    result['points_amelioration'] = result.get('points_amelioration', [])
    result['conseils_personnalises'] = result.get('conseils_personnalises', [])
    result['questions'] = result.get('questions', [])
    result['rang_classe'] = result.get('rang_classe', 'N/A')
    result['diagnostic_performance'] = result.get('diagnostic_performance', '')
    
    # Normaliser les questions avec leurs pourcentages
    if 'questions' in result:
        normalized_questions = []
        for question in result['questions']:
            normalized_question = _normalize_question_report_data(question)
            normalized_questions.append(normalized_question)
        result['questions'] = normalized_questions
    
    # Assurer la compatibilitÃ© avec l'alias
    result['questions_avec_commentaires'] = result.get('questions_avec_commentaires', result['questions'])
    
    return result

def _normalize_question_report_data(question):
    """Normalise les donnÃ©es d'une question pour les rapports"""
    
    # Valeurs de base
    note = question.get('note', 0)
    note_max = question.get('note_max', question.get('points_total', 5))
    
    # Calculer le pourcentage si manquant
    if 'pourcentage_reussite' not in question and note_max > 0:
        question['pourcentage_reussite'] = round((note / note_max) * 100, 1)
    elif 'pourcentage_reussite' not in question:
        question['pourcentage_reussite'] = 0.0
    
    # Normaliser les autres champs
    question['numero'] = question.get('numero', 'N/A')
    question['intitule'] = question.get('intitule', 'Question sans titre')
    question['type'] = question.get('type', 'ouverte')
    question['commentaire_intelligent'] = question.get('commentaire_intelligent', question.get('commentaire', ''))
    question['conseil_personnalise'] = question.get('conseil_personnalise', '')
    
    return question

def _load_published_student_evaluations(evaluations, student_info):
    """Charge les Ã©valuations publiÃ©es pour l'Ã©tudiant avec normalisation"""
    
    published_evaluations = []
    
    for eval_info in evaluations:
        results_dir = Path(eval_info['dossier']) / "resultats"
        if results_dir.exists():
            student_folder = None
            for folder in results_dir.iterdir():
                if folder.is_dir():
                    if (student_info['nom'].lower() in folder.name.lower() and 
                        student_info['prenom'].lower() in folder.name.lower()):
                        student_folder = folder
                        break
            
            if student_folder:
                correction_file = student_folder / "correction_detaillee.json"
                if correction_file.exists():
                    try:
                        with open(correction_file, 'r', encoding='utf-8') as f:
                            result = json.load(f)
                            result['evaluation_info'] = eval_info
                            
                            # âœ… CORRECTION : Normaliser le rÃ©sultat avant utilisation
                            result = _normalize_student_report_result(result, eval_info)
                            
                            # VÃ‰RIFICATION DU STATUT DE PUBLICATION
                            publication_status = _get_publication_status(eval_info, result)
                            
                            if publication_status == 'publie':
                                published_evaluations.append(result)
                    except:
                        continue
    
    return published_evaluations

def _load_unpublished_student_evaluations(evaluations, student_info):
    """Charge les Ã©valuations non publiÃ©es pour l'Ã©tudiant avec normalisation"""
    
    unpublished_evaluations = []
    
    for eval_info in evaluations:
        results_dir = Path(eval_info['dossier']) / "resultats"
        if results_dir.exists():
            student_folder = None
            for folder in results_dir.iterdir():
                if folder.is_dir():
                    if (student_info['nom'].lower() in folder.name.lower() and 
                        student_info['prenom'].lower() in folder.name.lower()):
                        student_folder = folder
                        break
            
            if student_folder:
                correction_file = student_folder / "correction_detaillee.json"
                if correction_file.exists():
                    try:
                        with open(correction_file, 'r', encoding='utf-8') as f:
                            result = json.load(f)
                            result['evaluation_info'] = eval_info
                            
                            # âœ… CORRECTION : Normaliser le rÃ©sultat mÃªme s'il n'est pas publiÃ©
                            result = _normalize_student_report_result(result, eval_info)
                            
                            # VÃ‰RIFICATION DU STATUT DE PUBLICATION
                            publication_status = _get_publication_status(eval_info, result)
                            
                            if publication_status != 'publie':
                                unpublished_evaluations.append({
                                    'evaluation_info': eval_info,
                                    'statut_publication': publication_status,
                                    'result': result
                                })
                    except:
                        continue
    
    return unpublished_evaluations

def _get_publication_status(eval_info, result):
    """DÃ©termine le statut de publication d'un rÃ©sultat"""
    
    # PrioritÃ© 1: Statut dans le rÃ©sultat individuel
    if 'statut_publication' in result:
        return result['statut_publication']
    
    # PrioritÃ© 2: Statut global de l'Ã©valuation
    if 'statut_publication' in eval_info:
        return eval_info['statut_publication']
    
    # Par dÃ©faut: brouillon (non publiÃ©)
    return 'brouillon'

def _show_reports_status(published_evaluations, unpublished_evaluations):
    """Affiche le statut des rapports selon les publications"""
    
    total_corrections = len(published_evaluations) + len(unpublished_evaluations)
    
    if total_corrections == 0:
        st.info("ğŸ“­ Aucune Ã©valuation corrigÃ©e trouvÃ©e pour gÃ©nÃ©rer des rapports")
        
        # SUGGESTIONS
        st.markdown("---")
        st.write("ğŸ’¡ **Pour obtenir vos rapports :**")
        st.write("â€¢ Assurez-vous d'avoir soumis vos copies")
        st.write("â€¢ Attendez que votre professeur lance la correction")
        st.write("â€¢ Attendez que votre professeur publie les rÃ©sultats")
        st.write("â€¢ Consultez vos rÃ©sultats une fois publiÃ©s")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“Š Voir mes rÃ©sultats"):
                st.session_state.page_redirect = "ğŸ“Š Mes rÃ©sultats"
                st.rerun()
        with col2:
            if st.button("ğŸ“¤ Voir mes soumissions"):
                st.session_state.page_redirect = "ğŸ“‹ Mes soumissions"
                st.rerun()
        return
    
    # MÃ‰TRIQUES DE PUBLICATION POUR LES RAPPORTS
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ“Š Ã‰valuations corrigÃ©es", total_corrections)
    
    with col2:
        st.metric("ğŸ“„ Rapports disponibles", len(published_evaluations))
    
    with col3:
        st.metric("â³ Rapports en attente", len(unpublished_evaluations))
    
    # Message informatif selon la situation
    if len(published_evaluations) == 0 and len(unpublished_evaluations) > 0:
        st.warning("ğŸ“ **Aucun rapport disponible - Tous vos rÃ©sultats sont en attente de publication**")
        st.info("Les rapports seront gÃ©nÃ©rÃ©s automatiquement une fois que le professeur aura publiÃ© vos rÃ©sultats")
    elif len(published_evaluations) > 0 and len(unpublished_evaluations) > 0:
        st.success(f"ğŸ“„ **{len(published_evaluations)} rapport(s) disponible(s)**")
        st.info(f"ğŸ“ {len(unpublished_evaluations)} rapport(s) supplÃ©mentaire(s) seront disponibles aprÃ¨s publication")
    elif len(published_evaluations) > 0:
        st.success(f"ğŸ‰ **Tous vos rapports sont disponibles !**")

def _show_unpublished_reports_section(unpublished_evaluations):
    """Affiche la section des rapports non disponibles"""
    
    st.subheader("â³ Rapports en Attente de Publication")
    
    # Message explicatif
    st.info("""
    **ğŸ“‹ Rapports non disponibles**
    
    Ces Ã©valuations ont Ã©tÃ© corrigÃ©es mais les rÃ©sultats ne sont pas encore publiÃ©s.
    Vous pourrez gÃ©nÃ©rer vos rapports une fois que le professeur aura publiÃ© les rÃ©sultats.
    """)
    
    # Liste des rapports non disponibles
    for unpub_eval in unpublished_evaluations:
        eval_info = unpub_eval['evaluation_info']
        statut = unpub_eval['statut_publication']
        
        # IcÃ´ne selon le statut
        if statut == 'brouillon':
            status_icon = "ğŸ“"
            status_text = "RÃ©sultats en brouillon"
        elif statut == 'depublie':
            status_icon = "ğŸš«"
            status_text = "RÃ©sultats temporairement retirÃ©s"
        else:
            status_icon = "â³"
            status_text = "En attente de publication"
        
        with st.expander(f"{status_icon} {eval_info['titre']} - {eval_info['matiere']} ({status_text})", expanded=False):
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**ğŸ“… Date Ã©valuation :** {eval_info['date']}")
                st.write(f"**ğŸ‘¨â€ğŸ« Professeur :** {eval_info.get('professeur', 'Non spÃ©cifiÃ©')}")
                st.write(f"**ğŸ“Š Statut :** {status_text}")
            
            with col2:
                if statut == 'brouillon':
                    st.warning("ğŸ“ **Rapport non disponible** - RÃ©sultats en brouillon")
                    st.write("Le professeur n'a pas encore publiÃ© les rÃ©sultats")
                elif statut == 'depublie':
                    st.error("ğŸš« **Rapport temporairement indisponible** - RÃ©sultats retirÃ©s")
                    st.write("Le professeur a temporairement retirÃ© les rÃ©sultats")
                else:
                    st.info("â³ **Rapport en attente** - Publication en cours")
            
            # FonctionnalitÃ©s limitÃ©es
            st.write("**ğŸ”’ FonctionnalitÃ©s verrouillÃ©es :**")
            st.write("â€¢ âŒ GÃ©nÃ©ration de rapports PDF")
            st.write("â€¢ âŒ Analyses graphiques dÃ©taillÃ©es")
            st.write("â€¢ âŒ Plans de rÃ©vision personnalisÃ©s")
            st.write("â€¢ âŒ TÃ©lÃ©chargements de donnÃ©es")
            
            st.write("**ğŸ’¡ Que faire ?**")
            st.write("â€¢ Attendez que le professeur publie les rÃ©sultats")
            st.write("â€¢ Contactez votre professeur pour connaÃ®tre le dÃ©lai")
            st.write("â€¢ Actualisez rÃ©guliÃ¨rement cette page")
    
    # Bouton d'actualisation
    st.markdown("---")
    if st.button("ğŸ”„ VÃ©rifier les publications", type="primary"):
        clear_all_cache()
        st.rerun()

def _display_report_section(eval_result, eval_info, student_info):
    """Affiche une section de rapport pour chaque Ã©valuation publiÃ©e avec gestion dÃ©fensive"""
    
    # âœ… CORRECTION : AccÃ¨s dÃ©fensif au pourcentage (maintenant normalisÃ©)
    pourcentage = eval_result.get('pourcentage', 0)
    if pourcentage >= 80:
        perf_icon = "ğŸ†"
        perf_text = "Excellent"
    elif pourcentage >= 70:
        perf_icon = "ğŸŒŸ"
        perf_text = "TrÃ¨s bien"
    elif pourcentage >= 60:
        perf_icon = "ğŸ‘"
        perf_text = "Bien"
    else:
        perf_icon = "ğŸ“ˆ"
        perf_text = "Ã€ amÃ©liorer"
    
    # Date de publication
    date_publication = eval_info.get('date_publication', 'Date inconnue')
    if date_publication != 'Date inconnue':
        try:
            date_formatted = datetime.fromisoformat(date_publication).strftime('%d/%m/%Y')
            publication_info = f"ğŸ“¢ PubliÃ© le {date_formatted}"
        except:
            publication_info = "ğŸ“¢ PubliÃ©"
    else:
        publication_info = "ğŸ“¢ PubliÃ©"
    
    with st.expander(f"{perf_icon} {eval_info['titre']} - {eval_info['matiere']} ({eval_info['date']}) - {publication_info}", expanded=True):
        
        # RÃ‰SUMÃ‰ RAPIDE avec gestion dÃ©fensive
        col1, col2, col3 = st.columns(3)
        
        with col1:
            note_totale = eval_result.get('note_totale', 0)
            note_maximale = eval_result.get('note_maximale', 20)
            st.metric("Note", f"{note_totale:.1f}/{note_maximale:.0f}")
        with col2:
            st.metric("Performance", f"{perf_text}")
        with col3:
            questions_count = len(eval_result.get('questions_avec_commentaires', eval_result.get('questions', [])))
            st.metric("Questions", questions_count)
        
        st.markdown("---")
        
        # ONGLETS POUR LES DIFFÃ‰RENTES ANALYSES
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¥ TÃ©lÃ©chargements", "ğŸ“ˆ Graphiques", "ğŸ“‹ Plan de RÃ©vision", "ğŸ“Š Analyses"])
        
        with tab1:
            _display_download_section(eval_result, eval_info, student_info)
        
        with tab2:
            _display_detailed_graphs(eval_result, eval_info)
        
        with tab3:
            _display_revision_plan(eval_result, eval_info)
        
        with tab4:
            _display_detailed_analysis(eval_result, eval_info)

def _display_download_section(eval_result, eval_info, student_info):
    """Section de tÃ©lÃ©chargements pour rÃ©sultats publiÃ©s"""
    
    st.success("âœ… **Rapports disponibles (rÃ©sultats publiÃ©s)**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**ğŸ“„ Rapport Complet PDF**")
        st.write("â€¢ Page de garde")
        st.write("â€¢ Analyses dÃ©taillÃ©es")
        st.write("â€¢ Graphiques intÃ©grÃ©s")
        st.write("â€¢ Plan de rÃ©vision")
        
        _display_pdf_download_button(eval_result, eval_info, student_info, "complet")
    
    with col2:
        st.write("**ğŸ“‹ RÃ©sumÃ© ExÃ©cutif**")
        st.write("â€¢ Points essentiels")
        st.write("â€¢ Recommandations")
        st.write("â€¢ SynthÃ¨se performance")
        st.write("â€¢ Format condensÃ©")
        
        _display_pdf_download_button(eval_result, eval_info, student_info, "resume")
    
    with col3:
        st.write("**ğŸ“ Format Texte**")
        st.write("â€¢ Toujours disponible")
        st.write("â€¢ Compatible partout")
        st.write("â€¢ DonnÃ©es brutes")
        st.write("â€¢ Sauvegarde simple")
        
        _display_text_download_button(eval_result, eval_info, student_info)

def _display_detailed_graphs(eval_result, eval_info):
    """Affiche les graphiques dÃ©taillÃ©s de performance avec gestion dÃ©fensive"""
    
    st.write("**ğŸ“ˆ Analyse Graphique de vos Performances**")
    
    questions = eval_result.get('questions_avec_commentaires', eval_result.get('questions', []))
    
    if not questions:
        st.info("ğŸ“Š Pas de donnÃ©es dÃ©taillÃ©es disponibles pour les graphiques")
        return
    
    # DonnÃ©es pour les graphiques avec gestion dÃ©fensive
    question_labels = []
    scores = []
    max_scores = []
    
    for i, q in enumerate(questions):
        question_labels.append(f"Q{q.get('numero', i+1)}")
        
        # âœ… CORRECTION : AccÃ¨s dÃ©fensif aux donnÃ©es de question (maintenant normalisÃ©es)
        note = q.get('note', 0)
        note_max = q.get('note_max', q.get('points_total', 1))
        pourcentage = q.get('pourcentage_reussite', 0)
        
        scores.append(float(pourcentage))
        max_scores.append(100.0)  # 100% pour chaque question
    
    # Graphique en barres avec Streamlit
    st.write("**ğŸ“Š Performance par Question (%)**")
    
    if scores:  # VÃ©rifier qu'il y a des donnÃ©es
        df = pd.DataFrame({
            'Question': question_labels,
            'Votre Score (%)': scores,
            'Maximum (%)': max_scores
        })
        
        st.bar_chart(df.set_index('Question')[['Votre Score (%)']])
        
        # Tableau dÃ©taillÃ©
        st.write("**ğŸ“‹ DÃ©tail des Performances**")
        
        chart_data = []
        for i, (label, score, q) in enumerate(zip(question_labels, scores, questions)):
            niveau = _get_performance_level(score)
            chart_data.append({
                'Question': label,
                'Score': f"{score:.1f}%",
                'Note': f"{q.get('note', 0):.1f}/{q.get('note_max', q.get('points_total', 5)):.1f}",
                'Niveau': niveau,
                'Type': q.get('type', 'N/A').title()
            })
        
        df_detail = pd.DataFrame(chart_data)
        st.dataframe(df_detail, use_container_width=True, hide_index=True)
        
        # Statistiques
        if scores:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                moyenne = sum(scores) / len(scores)
                st.metric("ğŸ“Š Score moyen", f"{moyenne:.1f}%")
            
            with col2:
                meilleur = max(scores)
                st.metric("ğŸ† Meilleur", f"{meilleur:.1f}%")
            
            with col3:
                plus_faible = min(scores)
                st.metric("ğŸ“ˆ Plus faible", f"{plus_faible:.1f}%")
            
            with col4:
                excellentes = sum(1 for s in scores if s >= 90)
                st.metric("ğŸŒŸ Excellentes", f"{excellentes}/{len(scores)}")
    else:
        st.info("ğŸ“Š Aucune donnÃ©e de score disponible")

def _display_revision_plan(eval_result, eval_info):
    """Affiche le plan de rÃ©vision personnalisÃ© avec gestion dÃ©fensive"""
    
    st.write("**ğŸ“‹ Plan de RÃ©vision PersonnalisÃ©**")
    
    matiere = eval_info.get('matiere', 'MatiÃ¨re')
    questions = eval_result.get('questions_avec_commentaires', eval_result.get('questions', []))
    
    # Analyser les questions par niveau de performance avec gestion dÃ©fensive
    questions_urgentes = []
    questions_amelioration = []
    questions_consolidation = []
    
    for q in questions:
        # âœ… CORRECTION : AccÃ¨s dÃ©fensif au pourcentage (maintenant normalisÃ©)
        pourcentage = q.get('pourcentage_reussite', 0)
        
        if pourcentage < 40:
            questions_urgentes.append(q)
        elif pourcentage < 70:
            questions_amelioration.append(q)
        elif pourcentage < 90:
            questions_consolidation.append(q)
    
    # Plan structurÃ© par prioritÃ©s
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if questions_urgentes:
            st.error("ğŸš¨ **PRIORITÃ‰ 1 - URGENT**")
            st.write(f"**{len(questions_urgentes)} question(s) Ã  retravailler**")
            
            for q in questions_urgentes:
                numero = q.get('numero', 'N/A')
                pourcentage = q.get('pourcentage_reussite', 0)
                st.write(f"â€¢ **Q{numero}** ({pourcentage:.0f}%)")
                conseil = q.get('conseil_personnalise', "Revoir les concepts de base")
                st.caption(conseil)
        else:
            st.success("âœ… **Aucune rÃ©vision urgente**")
    
    with col2:
        if questions_amelioration:
            st.warning("ğŸ“ˆ **PRIORITÃ‰ 2 - AMÃ‰LIORATION**")
            st.write(f"**{len(questions_amelioration)} question(s) Ã  approfondir**")
            
            for q in questions_amelioration:
                numero = q.get('numero', 'N/A')
                pourcentage = q.get('pourcentage_reussite', 0)
                st.write(f"â€¢ **Q{numero}** ({pourcentage:.0f}%)")
                conseil = q.get('conseil_personnalise', "Ã€ approfondir")
                st.caption(conseil)
        else:
            st.info("â„¹ï¸ **Bases solides acquises**")
    
    with col3:
        if questions_consolidation:
            st.info("ğŸ¯ **PRIORITÃ‰ 3 - CONSOLIDATION**")
            st.write(f"**{len(questions_consolidation)} question(s) Ã  peaufiner**")
            
            for q in questions_consolidation:
                numero = q.get('numero', 'N/A')
                pourcentage = q.get('pourcentage_reussite', 0)
                st.write(f"â€¢ **Q{numero}** ({pourcentage:.0f}%)")
                conseil = q.get('conseil_personnalise', "Peaufiner les dÃ©tails")
                st.caption(conseil)
        else:
            st.success("ğŸ† **MaÃ®trise excellente**")
    
    # Planning temporel suggÃ©rÃ©
    st.markdown("---")
    st.write("**ğŸ“… Planning de RÃ©vision SuggÃ©rÃ©**")
    
    planning_data = [
        ["ğŸ“… **Semaine 1**", "ğŸš¨ PrioritÃ© 1", "RÃ©visions urgentes - Reprendre les bases"],
        ["ğŸ“… **Semaine 2**", "ğŸ“ˆ PrioritÃ© 2", "Approfondissements - Exercices supplÃ©mentaires"],
        ["ğŸ“… **Semaine 3**", "ğŸ¯ PrioritÃ© 3", "Consolidation - Peaufinage des dÃ©tails"],
        ["ğŸ“… **Semaine 4**", "ğŸ§ª Ã‰valuation", "Tests blancs - Auto-Ã©valuation"]
    ]
    
    for periode, objectif, actions in planning_data:
        col_p1, col_p2, col_p3 = st.columns([1, 1, 2])
        with col_p1:
            st.write(periode)
        with col_p2:
            st.write(objectif)
        with col_p3:
            st.write(actions)
    
    # TÃ©lÃ©chargement du plan
    st.markdown("---")
    plan_text = _generate_revision_plan_text(eval_result, eval_info, questions_urgentes, questions_amelioration, questions_consolidation)
    
    eval_id = eval_info.get('id_evaluation', f"eval_{hash(eval_info['titre'])}")
    st.download_button(
        label="ğŸ“¥ TÃ©lÃ©charger Plan de RÃ©vision",
        data=plan_text,
        file_name=f"Plan_Revision_{eval_info.get('matiere', 'Matiere')}_{eval_info.get('date', '2024')}.txt",
        mime="text/plain",
        key=f"download_plan_{eval_id}"
    )

def _display_detailed_analysis(eval_result, eval_info):
    """Affiche l'analyse dÃ©taillÃ©e avancÃ©e avec gestion dÃ©fensive"""
    
    st.write("**ğŸ“Š Analyse DÃ©taillÃ©e AvancÃ©e**")
    
    questions = eval_result.get('questions_avec_commentaires', eval_result.get('questions', []))
    
    if not questions:
        st.info("ğŸ“Š Pas de donnÃ©es dÃ©taillÃ©es disponibles")
        return
    
    # Analyse par type de question avec gestion dÃ©fensive
    types_questions = {}
    for q in questions:
        q_type = q.get('type', 'ouverte')
        if q_type not in types_questions:
            types_questions[q_type] = {'total': 0, 'score_total': 0, 'questions': []}
        
        # âœ… CORRECTION : AccÃ¨s dÃ©fensif au pourcentage (maintenant normalisÃ©)
        pourcentage = q.get('pourcentage_reussite', 0)
        
        types_questions[q_type]['total'] += 1
        types_questions[q_type]['score_total'] += float(pourcentage)
        types_questions[q_type]['questions'].append(q)
    
    st.write("**ğŸ¯ Performance par Type de Question**")
    
    for q_type, data in types_questions.items():
        moyenne_type = data['score_total'] / data['total'] if data['total'] > 0 else 0
        
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            st.write(f"**{q_type.title()}**")
        
        with col2:
            st.write(f"Moyenne: {moyenne_type:.1f}%")
        
        with col3:
            st.write(f"({data['total']} question(s))")
        
        # Barre de progression
        progress_value = max(0, min(100, moyenne_type)) / 100
        st.progress(progress_value, text=f"MaÃ®trise {q_type}: {moyenne_type:.1f}%")
    
    # Recommandations par type
    st.markdown("---")
    st.write("**ğŸ’¡ Recommandations par Type de Question**")
    
    for q_type, data in types_questions.items():
        moyenne_type = data['score_total'] / data['total'] if data['total'] > 0 else 0
        
        if moyenne_type < 60:
            st.warning(f"ğŸ“ˆ **{q_type.title()}** : Travail nÃ©cessaire sur ce type d'exercice")
            recommandations = _get_type_recommendations(q_type, "faible")
        elif moyenne_type < 80:
            st.info(f"ğŸ”„ **{q_type.title()}** : Bonne base, Ã  approfondir")
            recommandations = _get_type_recommendations(q_type, "moyen")
        else:
            st.success(f"ğŸ† **{q_type.title()}** : Excellente maÃ®trise")
            recommandations = _get_type_recommendations(q_type, "excellent")
        
        for rec in recommandations:
            st.write(f"  â€¢ {rec}")

def _display_pdf_download_button(eval_result, eval_info, student_info, report_type):
    """Bouton de tÃ©lÃ©chargement PDF pour rÃ©sultats publiÃ©s"""
    
    eval_id = eval_info.get('id_evaluation', f"eval_{hash(eval_info['titre'])}")
    student_key = f"{student_info['nom']}_{student_info['prenom']}"
    button_key = f"pdf_{report_type}_{eval_id}_{student_key}"
    
    if report_type == "complet":
        button_label = "ğŸ“„ TÃ©lÃ©charger PDF Complet"
        filename_suffix = "Complet"
    else:
        button_label = "ğŸ“‹ TÃ©lÃ©charger RÃ©sumÃ© PDF"
        filename_suffix = "Resume"
    
    if st.button(button_label, key=button_key):
        
        with st.spinner(f"ğŸ”„ GÃ©nÃ©ration du rapport PDF..."):
            try:
                from utils.pdf_report_generator import generate_student_pdf_report
                
                pdf_data = generate_student_pdf_report(eval_result, eval_info, student_info)
                
                filename = f"Rapport_{filename_suffix}_{student_info['nom']}_{student_info['prenom']}_{eval_info.get('matiere', 'Matiere')}_{eval_info.get('date', '2024')}.pdf"
                filename = filename.replace(" ", "_").replace("/", "-").replace(":", "")
                
                st.download_button(
                    label=f"ğŸ“¥ TÃ©lÃ©charger {button_label.split()[-1]}",
                    data=pdf_data,
                    file_name=filename,
                    mime="application/pdf",
                    key=f"download_{button_key}"
                )
                
                st.success(f"âœ… PDF gÃ©nÃ©rÃ© ! Cliquez ci-dessus pour tÃ©lÃ©charger.")
                
            except ImportError:
                st.error("âŒ Module PDF non disponible")
                st.info("ğŸ’¡ Installez : `pip install reportlab`")
                
            except Exception as e:
                st.error(f"âŒ Erreur : {str(e)}")

def _display_text_download_button(eval_result, eval_info, student_info):
    """Bouton de tÃ©lÃ©chargement texte pour rÃ©sultats publiÃ©s"""
    
    eval_id = eval_info.get('id_evaluation', f"eval_{hash(eval_info['titre'])}")
    button_key = f"txt_{eval_id}"
    
    if st.button("ğŸ“ TÃ©lÃ©charger Format Texte", key=button_key):
        
        rapport_text = _generate_complete_text_report(eval_result, eval_info, student_info)
        
        filename = f"Rapport_{student_info['nom']}_{student_info['prenom']}_{eval_info.get('matiere', 'Matiere')}.txt"
        filename = filename.replace(" ", "_").replace("/", "-")
        
        st.download_button(
            label="ğŸ“¥ TÃ©lÃ©charger Rapport Texte",
            data=rapport_text,
            file_name=filename,
            mime="text/plain",
            key=f"download_txt_{button_key}"
        )
        
        st.success("âœ… Rapport texte prÃªt !")

def _generate_complete_text_report(eval_result, eval_info, student_info):
    """GÃ©nÃ¨re un rapport texte complet avec toutes les analyses"""
    
    # Date de publication
    date_publication = eval_info.get('date_publication', 'Date inconnue')
    if date_publication != 'Date inconnue':
        try:
            date_formatted = datetime.fromisoformat(date_publication).strftime('%d/%m/%Y Ã  %H:%M')
        except:
            date_formatted = date_publication
    else:
        date_formatted = 'Date inconnue'
    
    # âœ… CORRECTION : AccÃ¨s dÃ©fensif aux donnÃ©es de l'Ã©tudiant et de l'Ã©valuation
    nom = student_info.get('nom', 'Inconnu')
    prenom = student_info.get('prenom', 'Inconnu')
    numero = student_info.get('numero', 'N/A')
    titre = eval_info.get('titre', 'Sans titre')
    matiere = eval_info.get('matiere', 'MatiÃ¨re inconnue')
    date_eval = eval_info.get('date', 'Date inconnue')
    note_totale = eval_result.get('note_totale', 0)
    note_maximale = eval_result.get('note_maximale', 20)
    pourcentage = eval_result.get('pourcentage', 0)
    rang = eval_result.get('rang_classe', 'N/A')
    
    rapport = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    RAPPORT COMPLET DE CORRECTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ã‰TUDIANT : {prenom} {nom} ({numero})
Ã‰VALUATION : {titre} - {matiere}
DATE Ã‰VALUATION : {date_eval}
DATE PUBLICATION : {date_formatted}

RÃ‰SULTATS GÃ‰NÃ‰RAUX
==================
Note finale : {note_totale:.1f}/{note_maximale:.0f}
Pourcentage : {pourcentage:.1f}%
Rang classe : {rang}

STATUT DE PUBLICATION
====================
âœ… RÃ©sultats publiÃ©s et accessibles
ğŸ“Š Rapport gÃ©nÃ©rÃ© automatiquement
ğŸ“§ Ã‰tudiant notifiÃ© de la publication

[Contenu dÃ©taillÃ© avec analyses, graphiques textuels, plan de rÃ©vision...]
"""
    
    return rapport

def _generate_revision_plan_text(eval_result, eval_info, urgentes, amelioration, consolidation):
    """GÃ©nÃ¨re le plan de rÃ©vision en format texte avec gestion dÃ©fensive"""
    
    # âœ… CORRECTION : AccÃ¨s dÃ©fensif aux donnÃ©es
    matiere = eval_info.get('matiere', 'N/A')
    titre = eval_info.get('titre', 'Sans titre')
    nom = eval_result.get('etudiant_nom', 'Inconnu')
    prenom = eval_result.get('etudiant_prenom', 'Inconnu')
    
    plan = f"""
PLAN DE RÃ‰VISION PERSONNALISÃ‰
=============================

MatiÃ¨re : {matiere}
Ã‰valuation : {titre}
Ã‰tudiant : {prenom} {nom}
Statut : âœ… RÃ©sultats publiÃ©s

PRIORITÃ‰ 1 - RÃ‰VISIONS URGENTES ({len(urgentes)} question(s))
===============================================
"""
    
    for q in urgentes:
        numero = q.get('numero', 'N/A')
        conseil = q.get('conseil_personnalise', 'RÃ©vision nÃ©cessaire')
        plan += f"â€¢ Question {numero} : {conseil}\n"
    
    plan += f"""
PRIORITÃ‰ 2 - APPROFONDISSEMENTS ({len(amelioration)} question(s))
=====================================
"""
    
    for q in amelioration:
        numero = q.get('numero', 'N/A')
        conseil = q.get('conseil_personnalise', 'Ã€ approfondir')
        plan += f"â€¢ Question {numero} : {conseil}\n"
    
    plan += """
PLANNING SUGGÃ‰RÃ‰
================
Semaine 1 : Focus prioritÃ© 1
Semaine 2 : Travail prioritÃ© 2  
Semaine 3 : Consolidation
Semaine 4 : Auto-Ã©valuation
"""
    
    return plan

def _get_performance_level(pourcentage):
    """Retourne le niveau de performance avec gestion dÃ©fensive"""
    pourcentage = float(pourcentage) if pourcentage is not None else 0
    
    if pourcentage >= 90:
        return "ğŸ† Excellent"
    elif pourcentage >= 75:
        return "ğŸŒŸ TrÃ¨s bien"  
    elif pourcentage >= 60:
        return "ğŸ‘ Bien"
    elif pourcentage >= 40:
        return "ğŸ”„ Moyen"
    else:
        return "ğŸ“ˆ Ã€ amÃ©liorer"

def _get_type_recommendations(question_type, niveau):
    """Retourne des recommandations selon le type de question"""
    
    recommendations = {
        "calcul": {
            "excellent": ["Essayez des mÃ©thodes alternatives", "Aidez vos camarades"],
            "moyen": ["VÃ©rifiez vos calculs Ã©tape par Ã©tape", "Attention aux unitÃ©s"],
            "faible": ["Reprenez les formules de base", "EntraÃ®nez-vous sur des exemples simples"]
        },
        "demonstration": {
            "excellent": ["Explorez des dÃ©monstrations alternatives", "Travaillez la concision"],
            "moyen": ["Structurez mieux votre raisonnement", "Justifiez chaque Ã©tape"],
            "faible": ["Apprenez la mÃ©thodologie de dÃ©monstration", "Travaillez sur des exemples guidÃ©s"]
        },
        "qcm": {
            "excellent": ["Expliquez pourquoi les autres rÃ©ponses sont fausses"],
            "moyen": ["Lisez attentivement les nuances", "Ã‰liminez les rÃ©ponses Ã©videntes"],
            "faible": ["RÃ©visez les dÃ©finitions de base", "EntraÃ®nez-vous sur des QCM similaires"]
        },
        "ouverte": {
            "excellent": ["Enrichissez vos arguments", "Ajoutez des exemples"],
            "moyen": ["Structurez mieux vos idÃ©es", "DÃ©veloppez vos arguments"],
            "faible": ["Assurez-vous de comprendre la question", "Travaillez la rÃ©daction"]
        }
    }
    
    return recommendations.get(question_type, {}).get(niveau, ["Continuez vos efforts"])

if __name__ == "__main__":
    print("ğŸ“„ Page my_reports.py avec gestion dÃ©fensive des champs manquants prÃªte !")