"""
pages/student/my_reports.py - Version avec v√©rification de publication
====================================================================
Page de g√©n√©ration de rapports PDF - Respecte les statuts de publication
"""

import streamlit as st
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from utils.data_manager import get_evaluations_list, clear_all_cache
from utils.display_helpers import display_header

def show():
    """Page t√©l√©chargement de rapports avec v√©rification de publication"""
    if not st.session_state.get('student_logged_in', False):
        st.warning("‚ö†Ô∏è Veuillez vous connecter d'abord")
        return
    
    student_info = st.session_state.get('student_info', {})
    
    display_header("üìÑ Mes Rapports")
    
    # CHARGEMENT DES √âVALUATIONS CORRIG√âES ET PUBLI√âES
    evaluations = get_evaluations_list()
    published_evaluations = _load_published_student_evaluations(evaluations, student_info)
    unpublished_evaluations = _load_unpublished_student_evaluations(evaluations, student_info)
    
    if not evaluations:
        st.info("üì≠ Aucune √©valuation trouv√©e")
        if st.button("üîÑ Actualiser les donn√©es"):
            clear_all_cache()
            st.rerun()
        return
    
    # AFFICHAGE DU STATUT DES RAPPORTS
    _show_reports_status(published_evaluations, unpublished_evaluations)
    
    # AFFICHAGE DES RAPPORTS DISPONIBLES (PUBLI√âS)
    if published_evaluations:
        st.markdown("---")
        st.subheader(f"üìä {len(published_evaluations)} Rapport(s) Disponible(s)")
        
        # LISTE DES RAPPORTS DISPONIBLES
        for eval_result in published_evaluations:
            eval_info = eval_result['evaluation_info']
            _display_report_section(eval_result, eval_info, student_info)
    
    # AFFICHAGE DES RAPPORTS NON DISPONIBLES (NON PUBLI√âS)
    if unpublished_evaluations:
        st.markdown("---")
        _show_unpublished_reports_section(unpublished_evaluations)

def _load_published_student_evaluations(evaluations, student_info):
    """Charge les √©valuations publi√©es pour l'√©tudiant"""
    
    published_evaluations = []
    
    for eval_info in evaluations:
        results_dir = Path(eval_info['dossier']) / "resultats"
        if results_dir.exists():
            student_folder = None
            for folder in results_dir.iterdir():
                if folder.is_dir():
                    if (student_info['nom'].lower() in folder.name.lower() and 
                        student_info['prenom'].lower() in folder.name.lower()):
                        student_folder = folder
                        break
            
            if student_folder:
                correction_file = student_folder / "correction_detaillee.json"
                if correction_file.exists():
                    try:
                        with open(correction_file, 'r', encoding='utf-8') as f:
                            result = json.load(f)
                            result['evaluation_info'] = eval_info
                            
                            # V√âRIFICATION DU STATUT DE PUBLICATION
                            publication_status = _get_publication_status(eval_info, result)
                            
                            if publication_status == 'publie':
                                published_evaluations.append(result)
                    except:
                        continue
    
    return published_evaluations

def _load_unpublished_student_evaluations(evaluations, student_info):
    """Charge les √©valuations non publi√©es pour l'√©tudiant"""
    
    unpublished_evaluations = []
    
    for eval_info in evaluations:
        results_dir = Path(eval_info['dossier']) / "resultats"
        if results_dir.exists():
            student_folder = None
            for folder in results_dir.iterdir():
                if folder.is_dir():
                    if (student_info['nom'].lower() in folder.name.lower() and 
                        student_info['prenom'].lower() in folder.name.lower()):
                        student_folder = folder
                        break
            
            if student_folder:
                correction_file = student_folder / "correction_detaillee.json"
                if correction_file.exists():
                    try:
                        with open(correction_file, 'r', encoding='utf-8') as f:
                            result = json.load(f)
                            result['evaluation_info'] = eval_info
                            
                            # V√âRIFICATION DU STATUT DE PUBLICATION
                            publication_status = _get_publication_status(eval_info, result)
                            
                            if publication_status != 'publie':
                                unpublished_evaluations.append({
                                    'evaluation_info': eval_info,
                                    'statut_publication': publication_status,
                                    'result': result
                                })
                    except:
                        continue
    
    return unpublished_evaluations

def _get_publication_status(eval_info, result):
    """D√©termine le statut de publication d'un r√©sultat"""
    
    # Priorit√© 1: Statut dans le r√©sultat individuel
    if 'statut_publication' in result:
        return result['statut_publication']
    
    # Priorit√© 2: Statut global de l'√©valuation
    if 'statut_publication' in eval_info:
        return eval_info['statut_publication']
    
    # Par d√©faut: brouillon (non publi√©)
    return 'brouillon'

def _show_reports_status(published_evaluations, unpublished_evaluations):
    """Affiche le statut des rapports selon les publications"""
    
    total_corrections = len(published_evaluations) + len(unpublished_evaluations)
    
    if total_corrections == 0:
        st.info("üì≠ Aucune √©valuation corrig√©e trouv√©e pour g√©n√©rer des rapports")
        
        # SUGGESTIONS
        st.markdown("---")
        st.write("üí° **Pour obtenir vos rapports :**")
        st.write("‚Ä¢ Assurez-vous d'avoir soumis vos copies")
        st.write("‚Ä¢ Attendez que votre professeur lance la correction")
        st.write("‚Ä¢ Attendez que votre professeur publie les r√©sultats")
        st.write("‚Ä¢ Consultez vos r√©sultats une fois publi√©s")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üìä Voir mes r√©sultats"):
                st.session_state.page_redirect = "üìä Mes r√©sultats"
                st.rerun()
        with col2:
            if st.button("üì§ Voir mes soumissions"):
                st.session_state.page_redirect = "üìã Mes soumissions"
                st.rerun()
        return
    
    # M√âTRIQUES DE PUBLICATION POUR LES RAPPORTS
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üìä √âvaluations corrig√©es", total_corrections)
    
    with col2:
        st.metric("üìÑ Rapports disponibles", len(published_evaluations))
    
    with col3:
        st.metric("‚è≥ Rapports en attente", len(unpublished_evaluations))
    
    # Message informatif selon la situation
    if len(published_evaluations) == 0 and len(unpublished_evaluations) > 0:
        st.warning("üìù **Aucun rapport disponible - Tous vos r√©sultats sont en attente de publication**")
        st.info("Les rapports seront g√©n√©r√©s automatiquement une fois que le professeur aura publi√© vos r√©sultats")
    elif len(published_evaluations) > 0 and len(unpublished_evaluations) > 0:
        st.success(f"üìÑ **{len(published_evaluations)} rapport(s) disponible(s)**")
        st.info(f"üìù {len(unpublished_evaluations)} rapport(s) suppl√©mentaire(s) seront disponibles apr√®s publication")
    elif len(published_evaluations) > 0:
        st.success(f"üéâ **Tous vos rapports sont disponibles !**")

def _show_unpublished_reports_section(unpublished_evaluations):
    """Affiche la section des rapports non disponibles"""
    
    st.subheader("‚è≥ Rapports en Attente de Publication")
    
    # Message explicatif
    st.info("""
    **üìã Rapports non disponibles**
    
    Ces √©valuations ont √©t√© corrig√©es mais les r√©sultats ne sont pas encore publi√©s.
    Vous pourrez g√©n√©rer vos rapports une fois que le professeur aura publi√© les r√©sultats.
    """)
    
    # Liste des rapports non disponibles
    for unpub_eval in unpublished_evaluations:
        eval_info = unpub_eval['evaluation_info']
        statut = unpub_eval['statut_publication']
        
        # Ic√¥ne selon le statut
        if statut == 'brouillon':
            status_icon = "üìù"
            status_text = "R√©sultats en brouillon"
        elif statut == 'depublie':
            status_icon = "üö´"
            status_text = "R√©sultats temporairement retir√©s"
        else:
            status_icon = "‚è≥"
            status_text = "En attente de publication"
        
        with st.expander(f"{status_icon} {eval_info['titre']} - {eval_info['matiere']} ({status_text})", expanded=False):
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**üìÖ Date √©valuation :** {eval_info['date']}")
                st.write(f"**üë®‚Äçüè´ Professeur :** {eval_info['professeur']}")
                st.write(f"**üìä Statut :** {status_text}")
            
            with col2:
                if statut == 'brouillon':
                    st.warning("üìù **Rapport non disponible** - R√©sultats en brouillon")
                    st.write("Le professeur n'a pas encore publi√© les r√©sultats")
                elif statut == 'depublie':
                    st.error("üö´ **Rapport temporairement indisponible** - R√©sultats retir√©s")
                    st.write("Le professeur a temporairement retir√© les r√©sultats")
                else:
                    st.info("‚è≥ **Rapport en attente** - Publication en cours")
            
            # Fonctionnalit√©s limit√©es
            st.write("**üîí Fonctionnalit√©s verrouill√©es :**")
            st.write("‚Ä¢ ‚ùå G√©n√©ration de rapports PDF")
            st.write("‚Ä¢ ‚ùå Analyses graphiques d√©taill√©es")
            st.write("‚Ä¢ ‚ùå Plans de r√©vision personnalis√©s")
            st.write("‚Ä¢ ‚ùå T√©l√©chargements de donn√©es")
            
            st.write("**üí° Que faire ?**")
            st.write("‚Ä¢ Attendez que le professeur publie les r√©sultats")
            st.write("‚Ä¢ Contactez votre professeur pour conna√Ætre le d√©lai")
            st.write("‚Ä¢ Actualisez r√©guli√®rement cette page")
    
    # Bouton d'actualisation
    st.markdown("---")
    if st.button("üîÑ V√©rifier les publications", type="primary"):
        clear_all_cache()
        st.rerun()

def _display_report_section(eval_result, eval_info, student_info):
    """Affiche une section de rapport pour chaque √©valuation publi√©e"""
    
    # Indicateur de performance
    pourcentage = eval_result['pourcentage']
    if pourcentage >= 80:
        perf_icon = "üèÜ"
        perf_text = "Excellent"
    elif pourcentage >= 70:
        perf_icon = "üåü"
        perf_text = "Tr√®s bien"
    elif pourcentage >= 60:
        perf_icon = "üëç"
        perf_text = "Bien"
    else:
        perf_icon = "üìà"
        perf_text = "√Ä am√©liorer"
    
    # Date de publication
    date_publication = eval_info.get('date_publication', 'Date inconnue')
    if date_publication != 'Date inconnue':
        try:
            date_formatted = datetime.fromisoformat(date_publication).strftime('%d/%m/%Y')
            publication_info = f"üì¢ Publi√© le {date_formatted}"
        except:
            publication_info = "üì¢ Publi√©"
    else:
        publication_info = "üì¢ Publi√©"
    
    with st.expander(f"{perf_icon} {eval_info['titre']} - {eval_info['matiere']} ({eval_info['date']}) - {publication_info}", expanded=True):
        
        # R√âSUM√â RAPIDE
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Note", f"{eval_result['note_totale']}/{eval_result.get('note_maximale', 20)}")
        with col2:
            st.metric("Performance", f"{perf_text}")
        with col3:
            questions_count = len(eval_result.get('questions_avec_commentaires', eval_result.get('questions', [])))
            st.metric("Questions", questions_count)
        
        st.markdown("---")
        
        # ONGLETS POUR LES DIFF√âRENTES ANALYSES
        tab1, tab2, tab3, tab4 = st.tabs(["üì• T√©l√©chargements", "üìà Graphiques", "üìã Plan de R√©vision", "üìä Analyses"])
        
        with tab1:
            _display_download_section(eval_result, eval_info, student_info)
        
        with tab2:
            _display_detailed_graphs(eval_result, eval_info)
        
        with tab3:
            _display_revision_plan(eval_result, eval_info)
        
        with tab4:
            _display_detailed_analysis(eval_result, eval_info)

def _display_download_section(eval_result, eval_info, student_info):
    """Section de t√©l√©chargements pour r√©sultats publi√©s"""
    
    st.success("‚úÖ **Rapports disponibles (r√©sultats publi√©s)**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**üìÑ Rapport Complet PDF**")
        st.write("‚Ä¢ Page de garde")
        st.write("‚Ä¢ Analyses d√©taill√©es")
        st.write("‚Ä¢ Graphiques int√©gr√©s")
        st.write("‚Ä¢ Plan de r√©vision")
        
        _display_pdf_download_button(eval_result, eval_info, student_info, "complet")
    
    with col2:
        st.write("**üìã R√©sum√© Ex√©cutif**")
        st.write("‚Ä¢ Points essentiels")
        st.write("‚Ä¢ Recommandations")
        st.write("‚Ä¢ Synth√®se performance")
        st.write("‚Ä¢ Format condens√©")
        
        _display_pdf_download_button(eval_result, eval_info, student_info, "resume")
    
    with col3:
        st.write("**üìù Format Texte**")
        st.write("‚Ä¢ Toujours disponible")
        st.write("‚Ä¢ Compatible partout")
        st.write("‚Ä¢ Donn√©es brutes")
        st.write("‚Ä¢ Sauvegarde simple")
        
        _display_text_download_button(eval_result, eval_info, student_info)

def _display_detailed_graphs(eval_result, eval_info):
    """Affiche les graphiques d√©taill√©s de performance"""
    
    st.write("**üìà Analyse Graphique de vos Performances**")
    
    questions = eval_result.get('questions_avec_commentaires', eval_result.get('questions', []))
    
    if not questions:
        st.info("üìä Pas de donn√©es d√©taill√©es disponibles pour les graphiques")
        return
    
    # Donn√©es pour les graphiques
    question_labels = []
    scores = []
    max_scores = []
    
    for i, q in enumerate(questions):
        question_labels.append(f"Q{q.get('numero', i+1)}")
        
        note = q.get('note', 0)
        note_max = q.get('note_max', q.get('points_total', 1))
        pourcentage = q.get('pourcentage_reussite', 0)
        
        if pourcentage == 0 and note_max > 0:
            pourcentage = (note / note_max) * 100
        
        scores.append(pourcentage)
        max_scores.append(100)  # 100% pour chaque question
    
    # Graphique en barres avec Streamlit
    st.write("**üìä Performance par Question (%)**")
    
    df = pd.DataFrame({
        'Question': question_labels,
        'Votre Score (%)': scores,
        'Maximum (%)': max_scores
    })
    
    st.bar_chart(df.set_index('Question')[['Votre Score (%)']])
    
    # Tableau d√©taill√©
    st.write("**üìã D√©tail des Performances**")
    
    chart_data = []
    for i, (label, score, q) in enumerate(zip(question_labels, scores, questions)):
        niveau = _get_performance_level(score)
        chart_data.append({
            'Question': label,
            'Score': f"{score:.1f}%",
            'Note': f"{q.get('note', 0)}/{q.get('note_max', 5)}",
            'Niveau': niveau,
            'Type': q.get('type', 'N/A').title()
        })
    
    df_detail = pd.DataFrame(chart_data)
    st.dataframe(df_detail, use_container_width=True, hide_index=True)
    
    # Statistiques
    if scores:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            moyenne = sum(scores) / len(scores)
            st.metric("üìä Score moyen", f"{moyenne:.1f}%")
        
        with col2:
            meilleur = max(scores)
            st.metric("üèÜ Meilleur", f"{meilleur:.1f}%")
        
        with col3:
            plus_faible = min(scores)
            st.metric("üìà Plus faible", f"{plus_faible:.1f}%")
        
        with col4:
            excellentes = sum(1 for s in scores if s >= 90)
            st.metric("üåü Excellentes", f"{excellentes}/{len(scores)}")

def _display_revision_plan(eval_result, eval_info):
    """Affiche le plan de r√©vision personnalis√©"""
    
    st.write("**üìã Plan de R√©vision Personnalis√©**")
    
    matiere = eval_info.get('matiere', 'Mati√®re')
    questions = eval_result.get('questions_avec_commentaires', eval_result.get('questions', []))
    
    # Analyser les questions par niveau de performance
    questions_urgentes = []
    questions_amelioration = []
    questions_consolidation = []
    
    for q in questions:
        pourcentage = q.get('pourcentage_reussite', 0)
        if pourcentage == 0:
            note = q.get('note', 0)
            note_max = q.get('note_max', q.get('points_total', 1))
            pourcentage = (note / note_max) * 100 if note_max > 0 else 0
        
        if pourcentage < 40:
            questions_urgentes.append(q)
        elif pourcentage < 70:
            questions_amelioration.append(q)
        elif pourcentage < 90:
            questions_consolidation.append(q)
    
    # Plan structur√© par priorit√©s
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if questions_urgentes:
            st.error("üö® **PRIORIT√â 1 - URGENT**")
            st.write(f"**{len(questions_urgentes)} question(s) √† retravailler**")
            
            for q in questions_urgentes:
                st.write(f"‚Ä¢ **Q{q.get('numero')}** ({q.get('pourcentage_reussite', 0):.0f}%)")
                conseil = q.get('conseil_personnalise', f"Revoir les concepts de base")
                st.caption(conseil)
        else:
            st.success("‚úÖ **Aucune r√©vision urgente**")
    
    with col2:
        if questions_amelioration:
            st.warning("üìà **PRIORIT√â 2 - AM√âLIORATION**")
            st.write(f"**{len(questions_amelioration)} question(s) √† approfondir**")
            
            for q in questions_amelioration:
                st.write(f"‚Ä¢ **Q{q.get('numero')}** ({q.get('pourcentage_reussite', 0):.0f}%)")
                conseil = q.get('conseil_personnalise', f"Approfondir ce concept")
                st.caption(conseil)
        else:
            st.info("‚ÑπÔ∏è **Bases solides acquises**")
    
    with col3:
        if questions_consolidation:
            st.info("üéØ **PRIORIT√â 3 - CONSOLIDATION**")
            st.write(f"**{len(questions_consolidation)} question(s) √† peaufiner**")
            
            for q in questions_consolidation:
                st.write(f"‚Ä¢ **Q{q.get('numero')}** ({q.get('pourcentage_reussite', 0):.0f}%)")
                conseil = q.get('conseil_personnalise', f"Peaufiner les d√©tails")
                st.caption(conseil)
        else:
            st.success("üèÜ **Ma√Ætrise excellente**")
    
    # Planning temporel sugg√©r√©
    st.markdown("---")
    st.write("**üìÖ Planning de R√©vision Sugg√©r√©**")
    
    planning_data = [
        ["üìÖ **Semaine 1**", "üö® Priorit√© 1", "R√©visions urgentes - Reprendre les bases"],
        ["üìÖ **Semaine 2**", "üìà Priorit√© 2", "Approfondissements - Exercices suppl√©mentaires"],
        ["üìÖ **Semaine 3**", "üéØ Priorit√© 3", "Consolidation - Peaufinage des d√©tails"],
        ["üìÖ **Semaine 4**", "üß™ √âvaluation", "Tests blancs - Auto-√©valuation"]
    ]
    
    for periode, objectif, actions in planning_data:
        col_p1, col_p2, col_p3 = st.columns([1, 1, 2])
        with col_p1:
            st.write(periode)
        with col_p2:
            st.write(objectif)
        with col_p3:
            st.write(actions)
    
    # T√©l√©chargement du plan
    st.markdown("---")
    plan_text = _generate_revision_plan_text(eval_result, eval_info, questions_urgentes, questions_amelioration, questions_consolidation)
    
    st.download_button(
        label="üì• T√©l√©charger Plan de R√©vision",
        data=plan_text,
        file_name=f"Plan_Revision_{eval_info.get('matiere', 'Matiere')}_{eval_info.get('date', '2024')}.txt",
        mime="text/plain",
        key=f"download_plan_{eval_info.get('id_evaluation')}"
    )

def _display_detailed_analysis(eval_result, eval_info):
    """Affiche l'analyse d√©taill√©e avanc√©e"""
    
    st.write("**üìä Analyse D√©taill√©e Avanc√©e**")
    
    questions = eval_result.get('questions_avec_commentaires', eval_result.get('questions', []))
    
    if not questions:
        st.info("üìä Pas de donn√©es d√©taill√©es disponibles")
        return
    
    # Analyse par type de question
    types_questions = {}
    for q in questions:
        q_type = q.get('type', 'ouverte')
        if q_type not in types_questions:
            types_questions[q_type] = {'total': 0, 'score_total': 0, 'questions': []}
        
        pourcentage = q.get('pourcentage_reussite', 0)
        if pourcentage == 0:
            note = q.get('note', 0)
            note_max = q.get('note_max', q.get('points_total', 1))
            pourcentage = (note / note_max) * 100 if note_max > 0 else 0
        
        types_questions[q_type]['total'] += 1
        types_questions[q_type]['score_total'] += pourcentage
        types_questions[q_type]['questions'].append(q)
    
    st.write("**üéØ Performance par Type de Question**")
    
    for q_type, data in types_questions.items():
        moyenne_type = data['score_total'] / data['total'] if data['total'] > 0 else 0
        
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            st.write(f"**{q_type.title()}**")
        
        with col2:
            st.write(f"Moyenne: {moyenne_type:.1f}%")
        
        with col3:
            st.write(f"({data['total']} question(s))")
        
        # Barre de progression
        st.progress(moyenne_type / 100, text=f"Ma√Ætrise {q_type}: {moyenne_type:.1f}%")
    
    # Recommandations par type
    st.markdown("---")
    st.write("**üí° Recommandations par Type de Question**")
    
    for q_type, data in types_questions.items():
        moyenne_type = data['score_total'] / data['total'] if data['total'] > 0 else 0
        
        if moyenne_type < 60:
            st.warning(f"üìà **{q_type.title()}** : Travail n√©cessaire sur ce type d'exercice")
            recommandations = _get_type_recommendations(q_type, "faible")
        elif moyenne_type < 80:
            st.info(f"üîÑ **{q_type.title()}** : Bonne base, √† approfondir")
            recommandations = _get_type_recommendations(q_type, "moyen")
        else:
            st.success(f"üèÜ **{q_type.title()}** : Excellente ma√Ætrise")
            recommandations = _get_type_recommendations(q_type, "excellent")
        
        for rec in recommandations:
            st.write(f"  ‚Ä¢ {rec}")

def _display_pdf_download_button(eval_result, eval_info, student_info, report_type):
    """Bouton de t√©l√©chargement PDF pour r√©sultats publi√©s"""
    
    eval_id = eval_info.get('id_evaluation', 'default')
    student_key = f"{student_info['nom']}_{student_info['prenom']}"
    button_key = f"pdf_{report_type}_{eval_id}_{student_key}"
    
    if report_type == "complet":
        button_label = "üìÑ T√©l√©charger PDF Complet"
        filename_suffix = "Complet"
    else:
        button_label = "üìã T√©l√©charger R√©sum√© PDF"
        filename_suffix = "Resume"
    
    if st.button(button_label, key=button_key):
        
        with st.spinner(f"üîÑ G√©n√©ration du rapport PDF..."):
            try:
                from utils.pdf_report_generator import generate_student_pdf_report
                
                pdf_data = generate_student_pdf_report(eval_result, eval_info, student_info)
                
                filename = f"Rapport_{filename_suffix}_{student_info['nom']}_{student_info['prenom']}_{eval_info.get('matiere', 'Matiere')}_{eval_info.get('date', '2024')}.pdf"
                filename = filename.replace(" ", "_").replace("/", "-").replace(":", "")
                
                st.download_button(
                    label=f"üì• T√©l√©charger {button_label.split()[-1]}",
                    data=pdf_data,
                    file_name=filename,
                    mime="application/pdf",
                    key=f"download_{button_key}"
                )
                
                st.success(f"‚úÖ PDF g√©n√©r√© ! Cliquez ci-dessus pour t√©l√©charger.")
                
            except ImportError:
                st.error("‚ùå Module PDF non disponible")
                st.info("üí° Installez : `pip install reportlab`")
                
            except Exception as e:
                st.error(f"‚ùå Erreur : {str(e)}")

def _display_text_download_button(eval_result, eval_info, student_info):
    """Bouton de t√©l√©chargement texte pour r√©sultats publi√©s"""
    
    eval_id = eval_info.get('id_evaluation', 'default')
    button_key = f"txt_{eval_id}"
    
    if st.button("üìù T√©l√©charger Format Texte", key=button_key):
        
        rapport_text = _generate_complete_text_report(eval_result, eval_info, student_info)
        
        filename = f"Rapport_{student_info['nom']}_{student_info['prenom']}_{eval_info.get('matiere', 'Matiere')}.txt"
        filename = filename.replace(" ", "_").replace("/", "-")
        
        st.download_button(
            label="üì• T√©l√©charger Rapport Texte",
            data=rapport_text,
            file_name=filename,
            mime="text/plain",
            key=f"download_txt_{button_key}"
        )
        
        st.success("‚úÖ Rapport texte pr√™t !")

def _generate_complete_text_report(eval_result, eval_info, student_info):
    """G√©n√®re un rapport texte complet avec toutes les analyses"""
    
    # Date de publication
    date_publication = eval_info.get('date_publication', 'Date inconnue')
    if date_publication != 'Date inconnue':
        try:
            date_formatted = datetime.fromisoformat(date_publication).strftime('%d/%m/%Y √† %H:%M')
        except:
            date_formatted = date_publication
    else:
        date_formatted = 'Date inconnue'
    
    rapport = f"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    RAPPORT COMPLET DE CORRECTION
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

√âTUDIANT : {student_info['prenom']} {student_info['nom']} ({student_info['numero']})
√âVALUATION : {eval_info['titre']} - {eval_info['matiere']}
DATE √âVALUATION : {eval_info['date']}
DATE PUBLICATION : {date_formatted}

R√âSULTATS G√âN√âRAUX
==================
Note finale : {eval_result['note_totale']}/{eval_result.get('note_maximale', 20)}
Pourcentage : {eval_result['pourcentage']:.1f}%
Rang classe : {eval_result.get('rang_classe', 'N/A')}

STATUT DE PUBLICATION
====================
‚úÖ R√©sultats publi√©s et accessibles
üìä Rapport g√©n√©r√© automatiquement
üìß √âtudiant notifi√© de la publication

[Contenu d√©taill√© avec analyses, graphiques textuels, plan de r√©vision...]
"""
    
    return rapport

def _generate_revision_plan_text(eval_result, eval_info, urgentes, amelioration, consolidation):
    """G√©n√®re le plan de r√©vision en format texte"""
    
    plan = f"""
PLAN DE R√âVISION PERSONNALIS√â
=============================

Mati√®re : {eval_info.get('matiere', 'N/A')}
√âvaluation : {eval_info['titre']}
√âtudiant : {eval_result.get('etudiant_prenom', '')} {eval_result.get('etudiant_nom', '')}
Statut : ‚úÖ R√©sultats publi√©s

PRIORIT√â 1 - R√âVISIONS URGENTES ({len(urgentes)} question(s))
===============================================
"""
    
    for q in urgentes:
        plan += f"‚Ä¢ Question {q.get('numero')} : {q.get('conseil_personnalise', 'R√©vision n√©cessaire')}\n"
    
    plan += f"""
PRIORIT√â 2 - APPROFONDISSEMENTS ({len(amelioration)} question(s))
=====================================
"""
    
    for q in amelioration:
        plan += f"‚Ä¢ Question {q.get('numero')} : {q.get('conseil_personnalise', '√Ä approfondir')}\n"
    
    plan += """
PLANNING SUGG√âR√â
================
Semaine 1 : Focus priorit√© 1
Semaine 2 : Travail priorit√© 2  
Semaine 3 : Consolidation
Semaine 4 : Auto-√©valuation
"""
    
    return plan

def _get_performance_level(pourcentage):
    """Retourne le niveau de performance"""
    if pourcentage >= 90:
        return "üèÜ Excellent"
    elif pourcentage >= 75:
        return "üåü Tr√®s bien"  
    elif pourcentage >= 60:
        return "üëç Bien"
    elif pourcentage >= 40:
        return "üîÑ Moyen"
    else:
        return "üìà √Ä am√©liorer"

def _get_type_recommendations(question_type, niveau):
    """Retourne des recommandations selon le type de question"""
    
    recommendations = {
        "calcul": {
            "excellent": ["Essayez des m√©thodes alternatives", "Aidez vos camarades"],
            "moyen": ["V√©rifiez vos calculs √©tape par √©tape", "Attention aux unit√©s"],
            "faible": ["Reprenez les formules de base", "Entra√Ænez-vous sur des exemples simples"]
        },
        "demonstration": {
            "excellent": ["Explorez des d√©monstrations alternatives", "Travaillez la concision"],
            "moyen": ["Structurez mieux votre raisonnement", "Justifiez chaque √©tape"],
            "faible": ["Apprenez la m√©thodologie de d√©monstration", "Travaillez sur des exemples guid√©s"]
        },
        "qcm": {
            "excellent": ["Expliquez pourquoi les autres r√©ponses sont fausses"],
            "moyen": ["Lisez attentivement les nuances", "√âliminez les r√©ponses √©videntes"],
            "faible": ["R√©visez les d√©finitions de base", "Entra√Ænez-vous sur des QCM similaires"]
        },
        "ouverte": {
            "excellent": ["Enrichissez vos arguments", "Ajoutez des exemples"],
            "moyen": ["Structurez mieux vos id√©es", "D√©veloppez vos arguments"],
            "faible": ["Assurez-vous de comprendre la question", "Travaillez la r√©daction"]
        }
    }
    
    return recommendations.get(question_type, {}).get(niveau, ["Continuez vos efforts"])

if __name__ == "__main__":
    print("üìÑ Page my_reports.py avec v√©rification de publication pr√™te !")