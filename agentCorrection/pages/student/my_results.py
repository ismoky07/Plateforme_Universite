"""
pages/student/my_results.py - Version avec vÃ©rification de publication
====================================================================
Page consultation des rÃ©sultats Ã©tudiants - Respecte les statuts de publication
"""

import streamlit as st
import json
from pathlib import Path
from datetime import datetime
from utils.data_manager import get_evaluations_list, clear_all_cache
from utils.display_helpers import display_header

def show():
    """Page consultation des rÃ©sultats avec vÃ©rification de publication"""
    if not st.session_state.get('student_logged_in', False):
        st.warning("âš ï¸ Veuillez vous connecter d'abord")
        return
    
    student_info = st.session_state.get('student_info', {})
    
    display_header("ğŸ“Š Mes RÃ©sultats")
    
    # CHARGEMENT DES DONNÃ‰ES AVEC VÃ‰RIFICATION DE PUBLICATION
    evaluations = get_evaluations_list()
    published_evaluations = []
    unpublished_evaluations = []
    
    for eval_info in evaluations:
        results_dir = Path(eval_info['dossier']) / "resultats"
        if results_dir.exists():
            student_folder = None
            for folder in results_dir.iterdir():
                if folder.is_dir():
                    if (student_info['nom'].lower() in folder.name.lower() and 
                        student_info['prenom'].lower() in folder.name.lower()):
                        student_folder = folder
                        break
            
            if student_folder:
                correction_file = student_folder / "correction_detaillee.json"
                if correction_file.exists():
                    try:
                        with open(correction_file, 'r', encoding='utf-8') as f:
                            result = json.load(f)
                            result['evaluation_info'] = eval_info
                            
                            # VÃ‰RIFICATION DU STATUT DE PUBLICATION
                            publication_status = _get_publication_status(eval_info, result)
                            
                            if publication_status == 'publie':
                                published_evaluations.append(result)
                            else:
                                unpublished_evaluations.append({
                                    'evaluation_info': eval_info,
                                    'statut_publication': publication_status,
                                    'result': result
                                })
                    except:
                        continue
    
    # AFFICHAGE DES INFORMATIONS SELON LES STATUTS
    _show_results_summary(published_evaluations, unpublished_evaluations)
    
    # AFFICHAGE DES RÃ‰SULTATS PUBLIÃ‰S
    if published_evaluations:
        st.markdown("---")
        st.subheader("âœ… RÃ©sultats PubliÃ©s")
        
        for eval_result in published_evaluations:
            eval_info = eval_result['evaluation_info']
            _display_published_result(eval_result, eval_info)
    
    # AFFICHAGE DES RÃ‰SULTATS NON PUBLIÃ‰S
    if unpublished_evaluations:
        st.markdown("---")
        _show_unpublished_results_section(unpublished_evaluations)

def _get_publication_status(eval_info, result):
    """DÃ©termine le statut de publication d'un rÃ©sultat"""
    
    # PrioritÃ© 1: Statut dans le rÃ©sultat individuel
    if 'statut_publication' in result:
        return result['statut_publication']
    
    # PrioritÃ© 2: Statut global de l'Ã©valuation
    if 'statut_publication' in eval_info:
        return eval_info['statut_publication']
    
    # Par dÃ©faut: brouillon (non publiÃ©)
    return 'brouillon'

def _show_results_summary(published_evaluations, unpublished_evaluations):
    """Affiche le rÃ©sumÃ© des rÃ©sultats selon les statuts de publication"""
    
    total_corrections = len(published_evaluations) + len(unpublished_evaluations)
    
    if total_corrections == 0:
        st.info("ğŸ“­ Aucune Ã©valuation corrigÃ©e trouvÃ©e pour votre profil")
        
        # Suggestions d'actions
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“¤ Voir mes soumissions"):
                st.session_state.page_redirect = "ğŸ“‹ Mes soumissions"
                st.rerun()
        with col2:
            if st.button("ğŸ”„ VÃ©rifier Ã  nouveau", type="secondary"):
                clear_all_cache()
                st.rerun()
        return
    
    # MÃ‰TRIQUES DE PUBLICATION
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“Š Ã‰valuations corrigÃ©es", total_corrections)
    
    with col2:
        st.metric("âœ… RÃ©sultats publiÃ©s", len(published_evaluations))
    
    with col3:
        st.metric("ğŸ“ En attente de publication", len(unpublished_evaluations))
    
    with col4:
        if published_evaluations:
            notes = [r['note_totale'] for r in published_evaluations]
            moyenne = sum(notes) / len(notes)
            st.metric("ğŸ“ˆ Moyenne publiÃ©e", f"{moyenne:.1f}/20")
        else:
            st.metric("ğŸ“ˆ Moyenne publiÃ©e", "N/A")
    
    # Message informatif selon la situation
    if len(published_evaluations) == 0 and len(unpublished_evaluations) > 0:
        st.info("ğŸ“ **Tous vos rÃ©sultats sont en attente de publication par le professeur**")
    elif len(published_evaluations) > 0 and len(unpublished_evaluations) > 0:
        st.success(f"âœ… **{len(published_evaluations)} rÃ©sultat(s) disponible(s), {len(unpublished_evaluations)} en attente**")
    elif len(published_evaluations) > 0:
        st.success(f"ğŸ‰ **Tous vos rÃ©sultats sont publiÃ©s !**")

def _display_published_result(eval_result, eval_info):
    """Affiche un rÃ©sultat publiÃ© avec tous les dÃ©tails"""
    
    # INDICATEUR DE PERFORMANCE
    pourcentage = eval_result['pourcentage']
    performance_icon, performance_text = _get_performance_indicator(pourcentage)
    
    # Date de publication
    date_publication = eval_info.get('date_publication', 'Date inconnue')
    if date_publication != 'Date inconnue':
        try:
            date_formatted = datetime.fromisoformat(date_publication).strftime('%d/%m/%Y')
            publication_info = f"ğŸ“¢ PubliÃ© le {date_formatted}"
        except:
            publication_info = "ğŸ“¢ PubliÃ©"
    else:
        publication_info = "ğŸ“¢ PubliÃ©"
    
    with st.expander(f"{performance_icon} {eval_info['titre']} - {eval_info['matiere']} ({eval_info['date']}) - {publication_info}", expanded=True):
        
        # MÃ‰TRIQUES PRINCIPALES
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Note obtenue", f"{eval_result['note_totale']}/{eval_result.get('note_maximale', 20)}")
        
        with col2:
            st.metric("Pourcentage", f"{eval_result['pourcentage']:.1f}%")
        
        with col3:
            rang = eval_result.get('rang_classe', 'N/A')
            st.metric("Rang classe", rang)
        
        with col4:
            st.metric("Performance", f"{performance_icon} {performance_text}")
        
        # DIAGNOSTIC IA
        if eval_result.get('diagnostic_performance'):
            st.info(f"ğŸ¯ **Diagnostic IA :** {eval_result['diagnostic_performance']}")
        
        # ANALYSE PAR QUESTION AVEC COMMENTAIRES INTELLIGENTS
        questions_data = eval_result.get('questions_avec_commentaires', eval_result.get('questions', []))
        if questions_data:
            st.markdown("---")
            st.subheader("ğŸ“ Commentaires par Question")
            
            # DÃ©tail de chaque question
            for question in questions_data:
                _display_question_feedback(question)
        
        # COMMENTAIRES GÃ‰NÃ‰RAUX
        if 'commentaires_generaux' in eval_result:
            st.markdown("---")
            st.write("**ğŸ’¬ Commentaire gÃ©nÃ©ral du professeur :**")
            st.info(eval_result['commentaires_generaux'])
        
        # POINTS FORTS ET AMÃ‰LIORATIONS
        col1, col2 = st.columns(2)
        
        with col1:
            if 'points_forts' in eval_result and eval_result['points_forts']:
                st.success("**ğŸ¯ Vos points forts :**")
                for point in eval_result['points_forts']:
                    st.write(f"â€¢ {point}")
        
        with col2:
            if 'points_amelioration' in eval_result and eval_result['points_amelioration']:
                st.warning("**ğŸ“ˆ Points Ã  amÃ©liorer :**")
                for point in eval_result['points_amelioration']:
                    st.write(f"â€¢ {point}")
        
        # CONSEILS PERSONNALISÃ‰S
        if 'conseils_personnalises' in eval_result and eval_result['conseils_personnalises']:
            st.markdown("---")
            st.write("**ğŸ’¡ Conseils personnalisÃ©s :**")
            for conseil in eval_result['conseils_personnalises']:
                st.write(f"â€¢ {conseil}")
        
        # ACTIONS DISPONIBLES
        st.markdown("---")
        col_action1, col_action2 = st.columns(2)
        
        with col_action1:
            if st.button(f"ğŸ“„ GÃ©nÃ©rer rapport", key=f"rapport_{eval_info['id_evaluation']}"):
                st.session_state.page_redirect = "ğŸ“„ Mes rapports"
                st.rerun()
        
        with col_action2:
            # Lien vers les soumissions
            if st.button(f"ğŸ“¤ Voir ma soumission", key=f"soumission_{eval_info['id_evaluation']}"):
                st.session_state.page_redirect = "ğŸ“‹ Mes soumissions"
                st.rerun()

def _show_unpublished_results_section(unpublished_evaluations):
    """Affiche la section des rÃ©sultats non publiÃ©s"""
    
    st.subheader("ğŸ“ RÃ©sultats en Attente de Publication")
    
    # Message explicatif
    st.info("""
    **ğŸ“‹ RÃ©sultats corrigÃ©s mais non publiÃ©s**
    
    Ces Ã©valuations ont Ã©tÃ© corrigÃ©es par votre professeur mais ne sont pas encore publiÃ©es.
    Vous pourrez consulter vos rÃ©sultats une fois que le professeur les aura publiÃ©s.
    """)
    
    # Liste des Ã©valuations non publiÃ©es
    for unpub_eval in unpublished_evaluations:
        eval_info = unpub_eval['evaluation_info']
        statut = unpub_eval['statut_publication']
        
        # IcÃ´ne selon le statut
        if statut == 'brouillon':
            status_icon = "ğŸ“"
            status_text = "En brouillon"
            status_color = "info"
        elif statut == 'depublie':
            status_icon = "ğŸš«"
            status_text = "Temporairement retirÃ©"
            status_color = "warning"
        else:
            status_icon = "â³"
            status_text = "En attente"
            status_color = "info"
        
        with st.expander(f"{status_icon} {eval_info['titre']} - {eval_info['matiere']} ({status_text})", expanded=False):
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**ğŸ“… Date Ã©valuation :** {eval_info['date']}")
                st.write(f"**ğŸ‘¨â€ğŸ« Professeur :** {eval_info['professeur']}")
                st.write(f"**ğŸ“Š Statut :** {status_text}")
            
            with col2:
                if statut == 'brouillon':
                    st.info("ğŸ“ **En brouillon** - Le professeur n'a pas encore publiÃ© les rÃ©sultats")
                elif statut == 'depublie':
                    st.warning("ğŸš« **Temporairement retirÃ©** - Le professeur a retirÃ© les rÃ©sultats temporairement")
                else:
                    st.info("â³ **En attente** - Publication en cours")
            
            # Actions limitÃ©es
            st.write("**ğŸ’¡ Actions disponibles :**")
            st.write("â€¢ Contactez votre professeur pour connaÃ®tre le dÃ©lai de publication")
            st.write("â€¢ Actualisez rÃ©guliÃ¨rement cette page")
            st.write("â€¢ Consultez vos autres rÃ©sultats dÃ©jÃ  publiÃ©s")
    
    # Bouton d'actualisation
    st.markdown("---")
    col_refresh1, col_refresh2 = st.columns(2)
    
    with col_refresh1:
        if st.button("ğŸ”„ Actualiser les rÃ©sultats", type="primary"):
            clear_all_cache()
            st.rerun()
    
    with col_refresh2:
        if st.button("ğŸ“§ Contacter le professeur"):
            st.info("ğŸ“§ FonctionnalitÃ© de contact Ã  implÃ©menter")

def _display_question_feedback(question):
    """Affiche le feedback pour une question"""
    numero = question.get('numero', 'N/A')
    intitule = question.get('intitule', 'Question sans titre')
    note = question.get('note', 0)
    note_max = question.get('note_max', question.get('points_total', 5))
    pourcentage = question.get('pourcentage_reussite', 0)
    
    # Si pas de pourcentage, calculer
    if pourcentage == 0 and note_max > 0:
        pourcentage = (note / note_max) * 100
    
    commentaire = question.get('commentaire_intelligent', question.get('commentaire', ''))
    conseil = question.get('conseil_personnalise', '')
    question_type = question.get('type', 'ouverte')
    
    # Indicateur de performance pour la question
    q_icon, q_color, q_level = _get_question_performance(pourcentage)
    
    # Container simple
    with st.container():
        # En-tÃªte de la question
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            st.write(f"**Question {numero}** - {question_type.title()}")
            st.caption(f"ğŸ“‹ {intitule}")
        
        with col2:
            st.write(f"**Note :** {note}/{note_max} pts")
            st.write(f"**Score :** {pourcentage:.1f}%")
        
        with col3:
            # Badge de performance
            if q_color == "success":
                st.success(f"{q_icon} {q_level}")
            elif q_color == "info":
                st.info(f"{q_icon} {q_level}")
            elif q_color == "warning":
                st.warning(f"{q_icon} {q_level}")
            else:
                st.error(f"{q_icon} {q_level}")
        
        # Barre de progression visuelle
        st.progress(pourcentage / 100, text=f"MaÃ®trise: {pourcentage:.1f}%")
        
        # Commentaire intelligent
        if commentaire:
            st.markdown("**ğŸ’­ Analyse dÃ©taillÃ©e :**")
            st.info(commentaire)
        
        # Conseil personnalisÃ©
        if conseil:
            st.markdown("**ğŸ’¡ Conseil personnalisÃ© :**")
            st.success(conseil)
        
        st.markdown("---")

def _get_performance_indicator(pourcentage):
    """Retourne l'icÃ´ne et le texte de performance"""
    if pourcentage >= 90:
        return "ğŸ†", "Excellent"
    elif pourcentage >= 80:
        return "ğŸŒŸ", "TrÃ¨s bien"
    elif pourcentage >= 70:
        return "ğŸ‘", "Bien"
    elif pourcentage >= 60:
        return "ğŸŸ¡", "Correct"
    elif pourcentage >= 40:
        return "ğŸŸ ", "Passable"
    else:
        return "ğŸ”´", "Insuffisant"

def _get_question_performance(pourcentage):
    """Retourne l'icÃ´ne, couleur et niveau pour une question"""
    if pourcentage >= 90:
        return "ğŸ†", "success", "Excellent"
    elif pourcentage >= 75:
        return "ğŸŒŸ", "success", "TrÃ¨s bien"
    elif pourcentage >= 60:
        return "ğŸ‘", "info", "Bien"
    elif pourcentage >= 40:
        return "ğŸ”„", "warning", "Moyen"
    elif pourcentage >= 20:
        return "âš ï¸", "warning", "Faible"
    else:
        return "ğŸš¨", "error", "TrÃ¨s faible"

if __name__ == "__main__":
    print("ğŸ“Š Page my_results.py avec vÃ©rification de publication prÃªte !")