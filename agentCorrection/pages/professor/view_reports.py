"""
pages/professor/view_reports.py - Version CORRIG√âE pour le champ pourcentage manquant
==================================================================================
CORRECTION : Gestion d√©fensive des champs manquants (pourcentage, note_maximale, etc.)
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from utils.data_manager import (
    get_evaluations_list, 
    get_correction_results, 
    clear_all_cache,
    publish_evaluation_results,
    unpublish_evaluation_results,
    get_evaluation_publication_status,
    debug_evaluation_files

)
from utils.display_helpers import display_header
from pathlib import Path
from datetime import datetime
import json

def show():
    """Page consultation des rapports avec gestion d√©fensive des champs manquants"""
    display_header("üìä Consulter les Rapports")
    
    # CHARGEMENT INTELLIGENT DES √âVALUATIONS
    evaluations = get_evaluations_list()
    corrected_evaluations = []
    
    for eval_info in evaluations:
        results_dir = Path(eval_info['dossier']) / "resultats"
        if results_dir.exists() and any(results_dir.iterdir()):
            corrected_evaluations.append(eval_info)
    
    if not corrected_evaluations:
        st.warning("‚ö†Ô∏è Aucune √©valuation corrig√©e trouv√©e.")
        return
    
    # S√âLECTION DE L'√âVALUATION
    if 'selected_eval' in st.session_state:
        selected_eval_dir = st.session_state.selected_eval
        selected_eval = next((e for e in corrected_evaluations if e['dossier'] == selected_eval_dir), corrected_evaluations[0])
        del st.session_state.selected_eval
    else:
        eval_options = {f"{e['titre']} - {e['matiere']} ({e['date']})": e for e in corrected_evaluations}
        selected_eval_name = st.selectbox("Choisir l'√©valuation", list(eval_options.keys()))
        selected_eval = eval_options[selected_eval_name]
    
    # CHARGEMENT DES R√âSULTATS AVEC NORMALISATION
    results = get_correction_results(selected_eval['dossier'])
    
    if not results:
        st.error("‚ùå Aucun r√©sultat trouv√© pour cette √©valuation")
        if st.button("üîÑ Recharger"):
            clear_all_cache()
            st.rerun()
        return
    
    # ‚úÖ CORRECTION : Normaliser tous les r√©sultats pour √©viter les erreurs de champs manquants
    results = _normalize_results(results, selected_eval)
    
    # AFFICHAGE DU SYST√àME DE PUBLICATION CORRIG√â
    st.markdown("---")
    _show_publication_system_fixed(selected_eval, results)
    
    # ONGLETS POUR DIFF√âRENTES VUES
    tab1, tab2, tab3, tab4 = st.tabs(["üìä Vue d'ensemble", "üìà Statistiques d√©taill√©es", "üë• R√©sultats individuels", "üìÅ T√©l√©chargements"])
    
    with tab1:
        _show_overview_tab(results, selected_eval)
    
    with tab2:
        _show_detailed_stats_tab(results)
    
    with tab3:
        _show_individual_results_tab(results)
    
    with tab4:
        _show_downloads_tab(results, selected_eval)

def _normalize_results(results, eval_info):
    """‚úÖ NOUVELLE FONCTION : Normalise tous les r√©sultats pour √©viter les erreurs de champs manquants"""
    
    normalized_results = []
    note_max_default = eval_info.get('note_totale', 20)
    
    for i, result in enumerate(results):
        # R√©cup√©rer les valeurs avec des d√©fauts s√ªrs
        note_totale = result.get('note_totale', 0.0)
        note_maximale = result.get('note_maximale', note_max_default)
        
        # Calculer le pourcentage si manquant
        if 'pourcentage' not in result:
            pourcentage = round((note_totale / note_maximale) * 100, 1) if note_maximale > 0 else 0.0
        else:
            pourcentage = result['pourcentage']
        
        # Normaliser le r√©sultat avec tous les champs requis
        normalized_result = {
            # Champs obligatoires avec d√©fauts s√ªrs
            'etudiant_nom': result.get('etudiant_nom', f'Etudiant{i+1}'),
            'etudiant_prenom': result.get('etudiant_prenom', f'Prenom{i+1}'),
            'note_totale': float(note_totale),
            'note_maximale': float(note_maximale),
            'pourcentage': float(pourcentage),
            'rang_classe': result.get('rang_classe', i+1),
            'timestamp': result.get('timestamp', result.get('date_correction', datetime.now().isoformat())),
            
            # Champs optionnels avec d√©fauts
            'commentaires_generaux': result.get('commentaires_generaux', result.get('commentaires', '')),
            'points_forts': result.get('points_forts', []),
            'points_amelioration': result.get('points_amelioration', []),
            'conseils_personnalises': result.get('conseils_personnalises', []),
            'questions': result.get('questions', []),
            'necessite_revision_humaine': result.get('necessite_revision_humaine', False),
            'statut_publication': result.get('statut_publication', 'brouillon'),
            'date_correction': result.get('date_correction', datetime.now().isoformat()),
            'methode_correction': result.get('methode_correction', 'standard'),
            
            # Gestion d√©fensive pour les structures imbriqu√©es
            'detection_triche': _normalize_detection_triche(result.get('detection_triche', {})),
            'qualite_correction': _normalize_qualite_correction(result.get('qualite_correction', {})),
        }
        
        # Conserver tous les autres champs existants
        for key, value in result.items():
            if key not in normalized_result:
                normalized_result[key] = value
        
        normalized_results.append(normalized_result)
    
    return normalized_results

def _normalize_detection_triche(detection_data):
    """Normalise les donn√©es de d√©tection de triche"""
    return {
        'similarite_detectee': detection_data.get('similarite_detectee', False),
        'score_max': detection_data.get('score_max', 0.0),
        'algorithme': detection_data.get('algorithme', 'standard')
    }

def _normalize_qualite_correction(qualite_data):
    """Normalise les donn√©es de qualit√© de correction"""
    return {
        'profil_utilise': qualite_data.get('profil_utilise', 'Standard'),
        'confiance_ocr': qualite_data.get('confiance_ocr', 0.8),
        'modele_ia': qualite_data.get('modele_ia', 'standard'),
        'verification_double': qualite_data.get('verification_double', False),
        'ecart_type': qualite_data.get('ecart_type', 0.0),
        'nombre_corrections': qualite_data.get('nombre_corrections', 1),
        'notes_individuelles': qualite_data.get('notes_individuelles', [])
    }

def _show_publication_system_fixed(eval_info, results):
    """Affiche le syst√®me de publication des r√©sultats - VERSION CORRIG√âE"""
    st.subheader("üì¢ Gestion de la Publication")
    
    # ‚úÖ CORRECTION : Utiliser la fonction du data_manager pour le statut
    publication_status = get_evaluation_publication_status(eval_info['dossier'])
    
    # DEBUG - Informations d√©taill√©es
    with st.expander("üîç DEBUG - Informations d√©taill√©es", expanded=False):
        st.write(f"**Statut d√©tect√© :** {publication_status}")
        st.write(f"**Dossier :** {eval_info['dossier']}")
        st.write(f"**Statut dans eval_info :** {eval_info.get('statut_publication', 'N/A')}")
        
        # V√©rifier les fichiers
        eval_path = Path(eval_info['dossier'])
        possible_files = [
            eval_path / "infos_evaluation.json",
            eval_path / "evaluation_info.json"
        ]
        
        st.write("**Fichiers d'info pr√©sents :**")
        for f in possible_files:
            if f.exists():
                st.write(f"‚úÖ {f.name}")
                try:
                    with open(f, 'r', encoding='utf-8') as file:
                        data = json.load(file)
                        st.write(f"   Statut dans fichier : {data.get('statut_publication', 'N/A')}")
                except:
                    st.write(f"   ‚ùå Erreur lecture")
            else:
                st.write(f"‚ùå {f.name}")
        
        if st.button("üîç Diagnostic complet"):
            debug_evaluation_files(eval_info['dossier'])
    
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        # Affichage du statut
        if publication_status == 'brouillon':
            st.warning("üìù **Statut :** Brouillon (non visible aux √©tudiants)")
            st.info("Les r√©sultats ne sont pas encore accessibles aux √©tudiants")
        elif publication_status == 'publie':
            st.success("‚úÖ **Statut :** Publi√© (visible aux √©tudiants)")
            date_pub = eval_info.get('date_publication', 'Date inconnue')
            if date_pub != 'Date inconnue':
                try:
                    date_formatted = datetime.fromisoformat(date_pub).strftime('%d/%m/%Y √† %H:%M')
                    st.info(f"üìÖ Publi√© le : {date_formatted}")
                except:
                    st.info(f"üìÖ Publi√© le : {date_pub}")
        else:  # depublie
            st.error("üö´ **Statut :** D√©publi√© (retir√© aux √©tudiants)")
            st.info("Les r√©sultats ont √©t√© temporairement retir√©s")
    
    with col2:
        # M√©triques de publication
        st.metric("üìÑ Copies corrig√©es", len(results))
        if publication_status == 'publie':
            st.metric("üëÅÔ∏è Visible aux √©tudiants", "OUI", delta="Publi√©")
        else:
            st.metric("üëÅÔ∏è Visible aux √©tudiants", "NON", delta="Priv√©")
    
    with col3:
        # Actions de publication CORRIG√âES
        if publication_status in ['brouillon', 'depublie']:
            if st.button("üì¢ PUBLIER les r√©sultats", type="primary", key="btn_publish", help="Rendre les r√©sultats visibles aux √©tudiants"):
                with st.spinner("Publication en cours..."):
                    if _publish_results_fixed(eval_info, results):
                        st.success("‚úÖ R√©sultats publi√©s avec succ√®s !")
                        st.balloons()
                        # Forcer le rechargement
                        st.session_state.force_reload = True
                        st.rerun()
                    else:
                        st.error("‚ùå Erreur lors de la publication")
        
        if publication_status == 'publie':
            if st.button("üö´ D√âPUBLIER les r√©sultats", key="btn_unpublish", help="Retirer temporairement les r√©sultats"):
                with st.spinner("D√©publication en cours..."):
                    if _unpublish_results_fixed(eval_info, results):
                        st.success("‚úÖ R√©sultats d√©publi√©s avec succ√®s !")
                        # Forcer le rechargement
                        st.session_state.force_reload = True
                        st.rerun()
                    else:
                        st.error("‚ùå Erreur lors de la d√©publication")
    
    # V√©rifier si un rechargement est n√©cessaire
    if st.session_state.get('force_reload', False):
        st.session_state.force_reload = False
        clear_all_cache()
        st.rerun()
    
    # Bouton de rechargement manuel
    if st.button("üîÑ Actualiser les donn√©es", key="btn_refresh"):
        clear_all_cache()
        st.rerun()
    
    # Informations suppl√©mentaires
    with st.expander("‚ÑπÔ∏è Informations sur la publication", expanded=False):
        st.write("**üîç Statuts de publication :**")
        st.write("‚Ä¢ **Brouillon** : R√©sultats non visibles aux √©tudiants (statut par d√©faut apr√®s correction)")
        st.write("‚Ä¢ **Publi√©** : R√©sultats accessibles aux √©tudiants via leur espace personnel")
        st.write("‚Ä¢ **D√©publi√©** : R√©sultats temporairement retir√©s (utile pour corrections)")
        
        st.write("\n**üìß Notifications automatiques :**")
        st.write("‚Ä¢ Les √©tudiants recevront un email lors de la publication")
        st.write("‚Ä¢ Seuls les √©tudiants concern√©s par cette √©valuation seront notifi√©s")
        
        st.write("\n**üîí S√©curit√© :**")
        st.write("‚Ä¢ Chaque √©tudiant ne peut voir que ses propres r√©sultats")
        st.write("‚Ä¢ Les r√©sultats sont chiffr√©s et s√©curis√©s")
        st.write("‚Ä¢ Historique des publications conserv√©")

def _publish_results_fixed(eval_info, results):
    """Publie les r√©sultats pour les √©tudiants - VERSION CORRIG√âE"""
    
    try:
        st.write("üîÑ D√©but de la publication...")
        
        # ‚úÖ CORRECTION : Utiliser la fonction du data_manager
        success = publish_evaluation_results(eval_info['dossier'], eval_info)
        
        if success:
            st.write("‚úÖ Publication r√©ussie via data_manager")
            return True
        else:
            st.error("‚ùå √âchec de la publication via data_manager")
            return False
        
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la publication : {str(e)}")
        return False

def _unpublish_results_fixed(eval_info, results):
    """D√©publie les r√©sultats (les retire aux √©tudiants) - VERSION CORRIG√âE"""
    
    try:
        st.write("üîÑ D√©but de la d√©publication...")
        
        # ‚úÖ CORRECTION : Utiliser la fonction du data_manager
        success = unpublish_evaluation_results(eval_info['dossier'], eval_info)
        
        if success:
            st.write("‚úÖ D√©publication r√©ussie via data_manager")
            
            # V√©rification imm√©diate
            new_status = get_evaluation_publication_status(eval_info['dossier'])
            st.write(f"üîç Nouveau statut d√©tect√© : {new_status}")
            
            return True
        else:
            st.error("‚ùå √âchec de la d√©publication via data_manager")
            return False
        
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la d√©publication : {str(e)}")
        st.write(f"üîç D√©tails de l'erreur : {e}")
        return False

def _show_overview_tab(results, selected_eval):
    """Affiche l'onglet vue d'ensemble avec gestion d√©fensive"""
    st.subheader("üìä Statistiques Globales")
    
    # ‚úÖ CORRECTION : Acc√®s d√©fensif aux notes
    notes = [float(r.get('note_totale', 0)) for r in results if r.get('note_totale') is not None]
    
    if not notes:
        st.error("‚ùå Aucune note valide trouv√©e")
        return
        
    moyenne = sum(notes) / len(notes)
    note_max = max(notes)
    note_min = min(notes)
    taux_reussite = len([n for n in notes if n >= 10]) / len(notes) * 100
    
    # M√âTRIQUES PRINCIPALES
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("üìÑ Copies", len(results))
    with col2:
        st.metric("üìä Moyenne", f"{moyenne:.2f}/20")
    with col3:
        st.metric("üèÜ Note max", f"{note_max:.1f}/20")
    with col4:
        st.metric("üìâ Note min", f"{note_min:.1f}/20")
    with col5:
        st.metric("‚úÖ Taux r√©ussite", f"{taux_reussite:.1f}%")
    
    # INDICATEUR DE PUBLICATION
    publication_status = get_evaluation_publication_status(selected_eval['dossier'])
    if publication_status == 'publie':
        st.success("üëÅÔ∏è **R√©sultats publi√©s** - Visibles aux √©tudiants")
    else:
        st.warning("üìù **R√©sultats en brouillon** - Non visibles aux √©tudiants")
    
    # GRAPHIQUE DE DISTRIBUTION
    st.markdown("---")
    st.subheader("üìà Distribution des Notes")
    
    fig = px.histogram(
        x=notes,
        nbins=10,
        title="Distribution des Notes de Classe",
        labels={'x': 'Note (/20)', 'y': 'Nombre d\'√©tudiants'},
        color_discrete_sequence=['#667eea']
    )
    fig.add_vline(x=moyenne, line_dash="dash", line_color="red", annotation_text=f"Moyenne: {moyenne:.2f}")
    fig.add_vline(x=10, line_dash="dot", line_color="green", annotation_text="Seuil r√©ussite: 10")
    
    st.plotly_chart(fig, use_container_width=True)
    
    # INDICATEURS DE QUALIT√â
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        revisions_needed = len([r for r in results if r.get('necessite_revision_humaine', False)])
        st.metric("‚ö†Ô∏è R√©visions n√©cessaires", revisions_needed)
    
    with col2:
        triche_detected = len([r for r in results if r.get('detection_triche', {}).get('similarite_detectee', False)])
        st.metric("üö® Triche d√©tect√©e", triche_detected)
    
    with col3:
        excellentes = len([n for n in notes if n >= 16])
        st.metric("üåü Notes excellentes", excellentes)

def _show_detailed_stats_tab(results):
    """Affiche l'onglet statistiques d√©taill√©es avec gestion d√©fensive"""
    st.subheader("üìà Analyses D√©taill√©es")
    
    # ‚úÖ CORRECTION : Acc√®s d√©fensif aux notes
    notes = [float(r.get('note_totale', 0)) for r in results if r.get('note_totale') is not None]
    
    if not notes:
        st.error("‚ùå Aucune note valide trouv√©e")
        return
    
    # R√âPARTITION PAR TRANCHES
    tranches = {
        "Excellent (16-20)": len([n for n in notes if n >= 16]),
        "Bien (14-16)": len([n for n in notes if 14 <= n < 16]),
        "Assez bien (12-14)": len([n for n in notes if 12 <= n < 14]),
        "Passable (10-12)": len([n for n in notes if 10 <= n < 12]),
        "Insuffisant (<10)": len([n for n in notes if n < 10])
    }
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig_pie = px.pie(
            values=list(tranches.values()),
            names=list(tranches.keys()),
            title="R√©partition par Niveau"
        )
        st.plotly_chart(fig_pie, use_container_width=True)
    
    with col2:
        fig_bar = px.bar(
            x=list(tranches.values()),
            y=list(tranches.keys()),
            orientation='h',
            title="Nombre d'√©tudiants par tranche",
            color=list(tranches.values()),
            color_continuous_scale='Viridis'
        )
        st.plotly_chart(fig_bar, use_container_width=True)
    
    # STATISTIQUES AVANC√âES
    st.markdown("---")
    col1, col2, col3, col4 = st.columns(4)
    
    import statistics
    
    with col1:
        mediane = statistics.median(notes)
        st.metric("üìä M√©diane", f"{mediane:.2f}")
    
    with col2:
        ecart_type = statistics.stdev(notes) if len(notes) > 1 else 0
        st.metric("üìè √âcart-type", f"{ecart_type:.2f}")
    
    with col3:
        q1 = statistics.quantiles(notes, n=4)[0] if len(notes) >= 4 else min(notes)
        st.metric("üìà 1er quartile", f"{q1:.2f}")
    
    with col4:
        q3 = statistics.quantiles(notes, n=4)[2] if len(notes) >= 4 else max(notes)
        st.metric("üìà 3√®me quartile", f"{q3:.2f}")

def _show_individual_results_tab(results):
    """Affiche l'onglet r√©sultats individuels avec gestion d√©fensive"""
    st.subheader("üë• R√©sultats Individuels")
    
    # Indicateur de publication
    publication_status = results[0].get('statut_publication', 'brouillon') if results else 'brouillon'
    
    if publication_status == 'publie':
        st.success("‚úÖ Ces r√©sultats sont visibles aux √©tudiants")
    else:
        st.warning("üìù Ces r√©sultats ne sont pas encore publi√©s aux √©tudiants")
    
    # ‚úÖ CORRECTION : Tableau avec acc√®s d√©fensif aux champs
    df_results = pd.DataFrame([
        {
            "Rang": r.get('rang_classe', 'N/A'),
            "Nom": r.get('etudiant_nom', 'Inconnu'),
            "Pr√©nom": r.get('etudiant_prenom', 'Inconnu'),
            "Note": f"{r.get('note_totale', 0):.1f}/{r.get('note_maximale', 20):.0f}",
            "Pourcentage": f"{r.get('pourcentage', 0):.1f}%",
            "R√©vision": "‚ö†Ô∏è" if r.get('necessite_revision_humaine', False) else "‚úÖ",
            "Triche": "üö®" if r.get('detection_triche', {}).get('similarite_detectee', False) else "‚úÖ",
            "Publi√©": "‚úÖ" if r.get('statut_publication', 'brouillon') == 'publie' else "üìù"
        }
        for r in sorted(results, key=lambda x: x.get('note_totale', 0), reverse=True)
    ])
    
    st.dataframe(df_results, use_container_width=True, hide_index=True)
    
    # RECHERCHE ET FILTRAGE
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        search_name = st.text_input("üîç Rechercher par nom", placeholder="DUPONT")
    
    with col2:
        min_note = st.number_input("Note minimum", 0.0, 20.0, 0.0)
    
    with col3:
        max_note = st.number_input("Note maximum", 0.0, 20.0, 20.0)
    
    # FILTRAGE avec gestion d√©fensive
    if search_name or min_note > 0 or max_note < 20:
        filtered_results = []
        for r in results:
            nom = r.get('etudiant_nom', '')
            note = r.get('note_totale', 0)
            
            if search_name and search_name.upper() not in nom.upper():
                continue
            if note < min_note or note > max_note:
                continue
            filtered_results.append(r)
        
        st.write(f"üìä {len(filtered_results)} r√©sultat(s) trouv√©(s)")
        
        if filtered_results:
            for r in filtered_results:
                status_icon = "‚úÖ" if r.get('statut_publication', 'brouillon') == 'publie' else "üìù"
                nom = r.get('etudiant_nom', 'Inconnu')
                prenom = r.get('etudiant_prenom', 'Inconnu')
                note = r.get('note_totale', 0)
                note_max = r.get('note_maximale', 20)
                
                with st.expander(f"{status_icon} {prenom} {nom} - {note:.1f}/{note_max:.0f}"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**Pourcentage :** {r.get('pourcentage', 0):.1f}%")
                        st.write(f"**Rang :** {r.get('rang_classe', 'N/A')}")
                        st.write(f"**Statut publication :** {r.get('statut_publication', 'brouillon')}")
                    with col2:
                        commentaires = r.get('commentaires_generaux', r.get('commentaires', ''))
                        if commentaires:
                            st.write(f"**Commentaire :** {commentaires}")

def _show_downloads_tab(results, selected_eval):
    """Affiche l'onglet t√©l√©chargements avec gestion d√©fensive"""
    st.subheader("üìÅ T√©l√©chargements")
    
    # Informations de publication
    publication_status = get_evaluation_publication_status(selected_eval['dossier'])
    
    if publication_status == 'publie':
        st.info("‚ÑπÔ∏è **R√©sultats publi√©s** - Les rapports incluent les donn√©es visibles aux √©tudiants")
    else:
        st.warning("‚ö†Ô∏è **R√©sultats non publi√©s** - Les rapports sont pour usage interne uniquement")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**üìä Rapport Professeur Global**")
        if st.button("üìä T√©l√©charger Excel", type="primary"):
            # ‚úÖ CORRECTION : DataFrame avec acc√®s d√©fensif
            df_export = pd.DataFrame([
                {
                    "Nom": r.get('etudiant_nom', 'Inconnu'),
                    "Pr√©nom": r.get('etudiant_prenom', 'Inconnu'),
                    "Note": r.get('note_totale', 0),
                    "Note_Max": r.get('note_maximale', 20),
                    "Pourcentage": r.get('pourcentage', 0),
                    "Rang": r.get('rang_classe', 'N/A'),
                    "Commentaires": r.get('commentaires_generaux', r.get('commentaires', '')),
                    "Revision_Necessaire": r.get('necessite_revision_humaine', False),
                    "Triche_Detectee": r.get('detection_triche', {}).get('similarite_detectee', False),
                    "Statut_Publication": r.get('statut_publication', 'brouillon'),
                    "Date_Correction": r.get('date_correction', ''),
                    "Methode_Correction": r.get('methode_correction', 'standard'),
                    "Ecart_Type": r.get('qualite_correction', {}).get('ecart_type', 0),
                    "Nombre_Corrections": r.get('qualite_correction', {}).get('nombre_corrections', 1),
                    "Publie": "OUI" if r.get('statut_publication', 'brouillon') == 'publie' else "NON"
                }
                for r in results
            ])
            
            # Cr√©er le fichier Excel en m√©moire
            from io import BytesIO
            excel_buffer = BytesIO()
            df_export.to_excel(excel_buffer, index=False, sheet_name="Resultats")
            excel_data = excel_buffer.getvalue()
            
            # Nom du fichier
            filename = f"Rapport_{selected_eval['titre']}_{selected_eval['date']}.xlsx"
            
            st.download_button(
                label="üì• T√©l√©charger le rapport Excel",
                data=excel_data,
                file_name=filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    
    with col2:
        st.write("**üìß Rapport de Publication**")
        if st.button("üìß T√©l√©charger rapport publication"):
            # Cr√©er rapport de publication
            publication_report = _create_publication_report(selected_eval, results)
            
            st.download_button(
                label="üì• T√©l√©charger rapport publication",
                data=publication_report,
                file_name=f"Publication_{selected_eval['titre']}.txt",
                mime="text/plain"
            )

def _create_publication_report(eval_info, results):
    """Cr√©e un rapport de publication avec gestion d√©fensive"""
    
    publication_status = get_evaluation_publication_status(eval_info['dossier'])
    
    # ‚úÖ CORRECTION : Calculs avec gestion d√©fensive
    notes_valides = [r.get('note_totale', 0) for r in results if r.get('note_totale') is not None]
    moyenne = sum(notes_valides) / len(notes_valides) if notes_valides else 0
    note_max = max(notes_valides) if notes_valides else 0
    note_min = min(notes_valides) if notes_valides else 0
    taux_reussite = len([n for n in notes_valides if n >= 10]) / len(notes_valides) * 100 if notes_valides else 0
    
    report = f"""
RAPPORT DE PUBLICATION - {eval_info.get('titre', 'Sans titre')}
{'='*50}

INFORMATIONS G√âN√âRALES
- √âvaluation : {eval_info.get('titre', 'Sans titre')}
- Mati√®re : {eval_info.get('matiere', 'Non sp√©cifi√©e')}
- Date : {eval_info.get('date', 'Non sp√©cifi√©e')}
- Professeur : {eval_info.get('professeur', 'Non sp√©cifi√©')}

STATUT DE PUBLICATION
- Statut actuel : {publication_status.upper()}
- Nombre de copies : {len(results)}
- Date de correction : {eval_info.get('date_correction', 'Non sp√©cifi√©e')}
"""
    
    if publication_status == 'publie':
        report += f"""
- Date de publication : {eval_info.get('date_publication', 'Non sp√©cifi√©e')}
- Publi√© par : {eval_info.get('publie_par', 'Non sp√©cifi√©')}
"""
    
    if publication_status == 'depublie':
        report += f"""
- Date de d√©publication : {eval_info.get('date_depublication', 'Non sp√©cifi√©e')}
- D√©publi√© par : {eval_info.get('depublie_par', 'Non sp√©cifi√©')}
"""
    
    report += f"""

STATISTIQUES
- Note moyenne : {moyenne:.2f}/20
- Note maximale : {note_max:.1f}/20
- Note minimale : {note_min:.1f}/20
- Taux de r√©ussite : {taux_reussite:.1f}%

D√âTAILS DES R√âSULTATS
"""
    
    # ‚úÖ CORRECTION : Tri avec gestion d√©fensive
    results_sorted = sorted(results, key=lambda x: x.get('note_totale', 0), reverse=True)
    for r in results_sorted:
        nom = r.get('etudiant_nom', 'Inconnu')
        prenom = r.get('etudiant_prenom', 'Inconnu')
        note = r.get('note_totale', 0)
        pourcentage = r.get('pourcentage', 0)
        report += f"- {prenom} {nom} : {note:.1f}/20 ({pourcentage:.1f}%)\n"
    
    return report

if __name__ == "__main__":
    print("üìä View Reports avec gestion d√©fensive des champs manquants pr√™t !")